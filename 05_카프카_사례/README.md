# 5장 카프카 사례

## 5.1 이 장의 내용

5장에선는 카프카 적용 사례를 소개한다. 카프카의 특징을 복습하면서 예로 든 사례에 카프카가 적합한 이유를 설명한다. 공개된 사례로 카프카가 실제 어떻게 이용되는지를 알아보자.

## 5.2 카프카 적용 사례

1장에서 소개한 대로 카프카는 미국 링크드인이 자사의 웹사이트를 방문하는 사용자의 호라동을 추적하기 위한 목적으로 개발했다. 당시 다른 제품에서는 할 수 없었던 것을 카프카로는 실현할 수 있었고, 카프카에 더 많은 기능이 추가되면서 카프카 적용 사례도 퍼져나가게 되었다. 먼저 카프카 사례부터 소개한다.

### 5.2.1 카프카의 대표적 기능

카프카의 대표적인 기능으로 떠올릴 수 있는 것은 메시지 큐 제품/로그 수집 제품/ETL 도구 등 예전부터 존재했던 몇몇 제품의 대체라고 할 수 있다. 대부분 '이전 제품에서는 더이상 취급하지 못할 정도로 대량의 데이터를 처리해야 할 때' 카프카를 검토했다고 생각하면 될 것이다.

여기서는 구체적으로 알 수 있도록 실제 사용 현장에서 카프카가 어떤 상황에서 사용되는지 살펴본다. 1장에서 언급한 바와 같이 카프카는 단순하면서도 유연한 아키텍처라서 다양하게 사용된다. 우선 카프카의 대표적 기능 5가지부터 알아보자.

- 데이터 허브<br>
  여러 시스템 사이에서 데이터를 상호 교환한다.

- 로그 수집<br>
  BI 도구를 이용한 리포팅과 인공지능 분석을 위해 여러 서버에서 생성된 로그를 수집하고 축적할 곳에 연결한다.

- 웹 활동 분석<br>
  실시간 대시보드와 이상 탐지/부정 검출 등 웹에서의 사용자 활동을 실시간으로 파악한다.

- 사물인터넷<br>
  센서 등 다양한 디바이스에서 보낸 데이터를 수신해서 처리한 후 디바이스에 송신한다.

- 이벤트 소싱<br>
  데이터에 대한 일련의 이벤트를 순차적으로 기록하고 CQRS 방식으로 대량의 이벤트를 유연하게 처리한다.

물론 여깃서 열거한 모든 기능과 특징을 전부 사용하는 경우는 드물다. 특정 기능이 어떤 사례에서는 중요하더라도 그것이 반드시 다른 사례에서도 중요시 된다고는 말할 수 없다. 카프카는 유연한 구조로 되어 있어서 각 사례마다 다른 요구 사항을 토대로 기능을 취사 선택하거나 또는 요구 사항에 맞게 설정해서 사용하는 경우가 많다.

### 5.2.2 카프카 특징 복습

카프카는 대량의 데이터를 '높은 처리량'으로 '실시간' 처리하기 위한 제품이다. 카프카가 링크드인에서 탄생했을 때부터 현재에 이르기까지 카프카의 아키텍처는 변함없이 데이터 상호 교환을 위한 기반으로 발전해왔다. 현재는 카프카가 데이터를 전달하는 **파이프라인** 그 자체를 구성하기 위한 기반이라고 말할 정도다. 다시 한 번 카프카로 실현할 수 있는 4가지를 살펴보자.

- 확장성 : 여러 서버로 확장(스케일 아웃) 구성할 수 있기 때문에 데이터 양에 따라 시스템 확장이 가능하다.
- 영속성 : 수신한 데이터를 '디스크에 유지'할 수 있기 때문에 언제라도 데이터를 읽을 수 있다.
- 유연성 : '연계할 수 있는 제품이 많기' 때문에 제품이나 시스템을 연결하는 허브 역할을 한다.
- 신뢰성 : '메시지 전달 보등'을 하므로 데이터 분실을 걱정하기 않아도 된다.

또한 데이터를 주고받을 뿐만 아니라 카프카의 기능과 다ㅏ른 제품을 결합함으로써 실시간으로 높은 처리량의 데이터를 처리할 수 있다. 따라서 간헐적으로 발생하는 데이터를 수신하여 그때마다 순차 처리하는 **스트림 처리**의 기반으로 카프카를 사용할 수 있다.

카프카는 위의 4가지를 실현하기 위한 아키텍쳐로 펍/섭 메시징 모델 기반이라는 점도 설명했다. 이에 따라 메시지 큐 모델과는 달리 동일한 메시시를 여러 곳에 전달하는, 이른바 **동보 전송**도 가능하다. 또한 2장에서도 다루었듯이 메시지를 토픽에 포함된 파티션 단위로 한정하면 메시지의 순서보증의 실현 또한 가능하다.

이러한 사항을 바탕으로 대량의 데이터를 처리해야 하는 전제하에, 카프카의 각 지응과 특징이 중시되는 상황을 정리하면 다음과 같다.

- 실시간<br>
  \- 긴급성이 요구되거나ㅏ 데이터를 즉시 사용하는 경우
- 동보 전송<br>
  \- 하나의 동일한 데이터를 후속의 여러 시스템에서 사용하는 경우. 데이터를 전달하는 관계 시스템이 단계적으로 증가하는 경우
- 영속성<br>
  \- 데이터를 버퍼링해야 하는 경우나 처리 시간 간격이 다른 복수의 처리와 관련된 경우
- 다수의 제휴 제품<br>
  \- 사용되는 제품이 균일하지 않고 다양한 접속을 필요로 하는 경우
- 송수신 제품<br>
  \- 데이터 손실이 허용되지 않는 경우
- 순서 보증<br>
  \- 데이터 소스에 있어 데이터의 생성 순서를 중시하여 순서에 따른 판단과 제어를 수반하는 경우

### 5.2.3 카프카 특징과 사례 대응

카프카의 기능과 특징을 앞서 언급한 5가지 사례에 맞춰 보았다. 표에서는 각 사례에서 중요시하는 항복에 O 표기했다. 원래 링크드인에서의 용도는 데이터 허브, 로그 수집, 웹 활동 분석 3가지를 합친 것이어서 모든 항목에 O가 있지만 여기에서는 이해하기 쉽게 분리해서 다룬다.

| 사례         | 실시간 | 동보 전송 | 영속성 | 다수의 제휴 제품 | 송수신 보증 | 순서 보증 |
| ------------ | ------ | --------- | ------ | ---------------- | ----------- | --------- |
| 데이터허브   |        | O         | O      | O                | O           |
| 로그 수집    |        |           | O      | O                | O           |
| 웹 활동 분석 | O      |           |        | O                | O           | O         |
| 사물 인터넷  | O      |           |        | O                |             |
| 이벤트 소싱  | O      |           | O      |                  | O           | O         |

## 5.3 데이터 허브

이 절에서는 사례 중 하나인 데이터 허브를 살펴본다 .여기서 데이터 허브란 여러 곳의 데이터소스가 되는 시스템에서 데이터를 수집하여 여러 시스템에 전달하는 아키텍처를 의미한다.

### 5.3.1 데이터 허브로 실현하고자 하는 것

비지니스에 있어서 IT 시스템은 IT 전문 기업뿐만 아니라 일반 기업에서도 많이 사용한다. 특히 사업 부문별로 업무 시스템화를 추진한 조직에는 부서마다 개별 시스템이 있는데, 이러한 개별 시스템은 각각 독립적으로 최적화되어 운용되는 경우가 많다. 이렇게 독립적으로 존재하는 시스템 사이에서는 효율적인 데이터 전달이 필요하다.

### 5.3.2 데이터 허브에서 해결해야 할 과제

데이터 허브가 없는 경우 어떤 문제가 있을지 생각해보자. 독립된 시스템이 많은 회사는 시스템 간 데이터 연계라는 큰 과제가 있다. 잠깐 생각하더라도 다음과 같은 사항을 고려해야 할 것이다.

- 데이터 형식은 CSV로 좋은지
- 송신 타이밍은 1일 1회로 좋은지
- 상대 시스템이 유지보수하는 동안 어떻게 할 것인지
- 장애가 발생했을 때 데이터를 잃지 않기 위해서 어떻게 할지

예를 들어 시스템에 있는 데이터를 다른 3개의 시스템으로 전송해야하는 경우 3개의 시스템별로 데이터 연계 방식을 조정해야한다. 이러한 것을 시스템 특성을 고려하여 조정하려면 상당한 노력이 필요하다.

게다가 1년 후에는 연계 시스템이 늘어날 수도 있다.

이 경우 앞서 실시했던 연계 시스템 간의 조정을 늘어난 시스템에도 적용하고 현재 문제없이 동작하고 있는 시스템에도 수정을 거쳐 안정적으로 가동시켜야 한다. 시스템이 많으면 많을수록 시스템 간의 접속 패턴과 변형이 많아져서 좀처럼 수습하기가 어렵다.

이처럼 시스템이 분리되어 시스템 간의 연계를 효율적으로 할 수 없는 상황을 사일로(silo)화됐다고 한다. 사일로화된 시스템은 IT 기술의 보급과 함께 전 세계적으로 많이 발생했다. 그리고 사일로화에 의한 문제를 해결하기 위한 솔루션도 많이 개발됐다. 시스템 사일로화에 의한 접속 수 증가에 따라 다음과 같은 과제를 해결해야 한다.

- 데이터 소스에서 생성된 동일한 데이터를 여러 시스템에서 이용한다.
- 후속 시스템마다 데이터를 필요로 하는 시기와 빈도가 다르다.
- 접속원이나 연결 시스템에서 이용되는 연계 방식이 제각각이다.(예: FTP 전송에 의한 파일 연계 규칙이 시스템마다 다르거나, JDBC 접속으로 연결되는 DBMS 제품이 여러 종류인 경우)
- 데이터 분실을 허용하지 않는다.

### 5.3.3 카프카로 데이터 허브 구현하기

사일로화를 해결하기 위한 개념의 하나로 데이터 허브 아키텍처가 있다. 데이터 허브 아키텍처란 데이터 소스가 되는 시스템에서 데이터를 수집하여 해당 데이터를 여러 시스템에 전달하는 아키텍처다.

데이터 허브 아키텍처에서는 시스템을 일대일로 연결하는 대신 모든 시스템이 데이터 허브에 데이터를 보내고 데이터 허브에서만 데이터를 받을 수 있도록 되어 있다. 이렇게 하면 시스템은 데이터를 데이터 허브에 보내는 것만 생각하면 되고, 데이터를 수신하는 시스템도 데이터 허브에서 데이터를 받는 것만 생각하면 된다. 카프카를 데이터 허브로 이용함으로써 다대다(M:N) 접속을 '모든 시스템은 카프카에 연결하기만 하면 된다'는 형태로 해결할 수 있다. 그 외의 과제도 카프카에서는 해결 가능하다.

- 동보 전송<br>
  \- 데이터 소스에서 생성된 동일 데이터를 여러 시스템에서 이용할 수 있다. 이는 펍/섭 메시징 모델로 착안했기 때문에 실현가능하다.
- 영속화<br>
  \- 데이터를 필요로 하는 시기와 빈도가 후속 시스템마다 다른 문제에 대해 카프카는 데이터를 영속화하고 버퍼링함으로써 임의의 시기에 추출할 수 있다.
- 다수의 연계 제품<br>
  \- Kafka Connect로 연계할 수 있는 제품이 다수 있기 때문에 접속원이나 연결 시스템에서 사용하는 제품이 다수라고 하더라도 이에 대응할 수 있는 가능성이 높다.
- 송수신 보증<br>
  \- 카프카는 데이터 분실이 허용되지 않는 요구 사항에 대해 송수신을 보증한다. At Least Once, Exactly Once 등 서로 다른 수준의 송수신 보증에도 대응할 수 있다.

이와 더불어 데이터 허브로서 시스템을 중개하려면 '단순히 데이터만 가져오기', '단순히 데이터만 모으기'만을 하는 것이 아니라 여러 시스템에 대해 '사용법에 맞게 사용하기 쉬운 방식으로 데이터를 보관하는 것'도 중요하다.

## 5.4 로그 수집

이 절에서는 사례 중 하나인 로그 수집에 대해 살펴본다.

### 5.4.1 로그 수집으로 실현하고자 하는 것

여러 서버에 존재하는 로그파일을 한 곳에서 보관하고 싶은 경우가 있다. 예를 들면 여러 로그의 결과를 모아서 BI 도구나 대시보드에서 시각화하고 싶은 경우다. 또는 집약한 로그를 이용하여 머신러닝을 구현하고 싶을 수도 있을 것이다. 더 간단하게는 여러 서버의 로그 내용을 확인하는데 그때마다 각 서버에 들어가 확인하는 것이 귀찮은 경우도 있다. 로그 수집을 간단한 것으로 생각할지도 모르겠지만 애플리케이션이 늘어나면서 외부와의 연계가 증가하면 로그 수집을 위한 노력도 증가한다. 이를 보다 편하게 하고 싶다는 생각은 매우 자연스러운 것이다.

### 5.4.2 로그 수집에서 해결해야 할 과제

로그 수집은 우선 여러 데이터 소스와 연결돼야 한다. 데이터 소스로 사용하는 제품이 동일하다면 그 제품에 특화된 것도 괜찮지만 다양한 제품과의 연계를 염두에 둬야 한다.

또한 '일괄적으로 일정 간격마다 축적'하는 것과 함께 '버퍼가 넘쳐 로그를 잃는 일'이 벌어지면 곤란하므로 대량의 로그를 받아 일정한 모음으로 집약하고 버퍼링하기 위한 장치가 필요하다.

마지막으로 로그 전달 시 로그를 잃어서는 안 된다는 점이 있따. 약간의 손실을 허용하는 경우도 있겠으나, 엄격한 트랜잭션 관리까지는 아니더라도 로그가 손실되어서는 안된다는 것이 현실적인 요구 사항이다.

### 5.4.3 카프카로 로그 수집하기

이러한 과제를 해결하는 데 있어 카프카가 유용한 점은 다음과 같다.

**다수의 연계 제품**

카프카에는 Producer API가있어 이를 이용하여 카프카와 접속하는 애플리케이션을 만들 수도 있다. 처음부터 애플리케이션을 작성하는 것이 힘들다면 단순히 서버 로그만을 집계하는 경우 Fluentd를 도입하여 Fluentd와 카프카 조합을 구성하는 것도 좋은 방법이다. 또한 Kafka Connect를 사용하는 경우는 컨플루언트 플랫폼이나 커뮤니티에서 제공되고 있는 여러 커넥터를 이용하여 카프카와 연계할 수 있다.

**영속화**

카프카는 데이터를 디스크에 영속화한다. 메모리 공간보다 더 큰 데이터라면 이를 디스크에 보관해 혹여 메모리 안에서 손실되거나 제외되더라도 나중에 읽을 수 있도록 되어있다. 카프카를 메모리 공간을 넘어서는 큰 용량의 버퍼로 이용할 수 있다는 점이 로그 수집에서 카프카를 이용하는 큰 이유라고 할 수 있다.

**송수신 보증**

링크드인의 사례처럼 At Least Once (적어도 한 번은 보내기) 수준의 송수신은 보증한다. 한편 약간의 손실을 허용하는 경우는 Ack를 반환하지 않음으로써 데이터 소스 쪽의 처리를 줄여 성능 향상을 우선할 수도 있다. 이와 같이 필요에 따라 조정 가능하다는 점도 장점이다.
<br><br>
참고로 로그 수집을 실현한 제품으로는 Scribe, Flume 같은 제품도 있으며 카프카도 이러한 제품을 의식하고 있따. 카프카가 Scribe나 Flume보다 나은 점을 꼽으라면 우수한 성능, 강한 내장애성(복제 가능), 종단 간 지연 시간이 낮은 점 등이다.

## 5.5 웹 활동 분석

사례 중 하나인 웹 활동 분석에 대해 살펴보자.

### 5.5.1 웹활동 분석으로 실현하고자 하는 것

웹 활동 분석을 웹사이트를 방문하는 사용자의 행동을 파악하여 마케팅에 활용하기 위한 작업이다. 사용자가 웹에서 클릭하는 활동은 기본적으로 모두 로그에 남으므로 사용자가 웹사이트의 페이지 사이를 어떤 식으로 이동했는지 파악할 수 있다.

웹 활동 분석의 대표적인 사례는 다음과 같은 것이 있으며, 이를 통해 실현하고 싶은 것 또한 매우 다양하다.

- 페이지 뷰와 전환율(성공율/구매율) 파악
- 개인화된 권장 사항
- 로얄 고객을 파악하는 고객 클러스터링
- A/B 테스트에 의한 웹사이트 개선

웹사이트 액세스 분석에서는 일정량의 로그 모음을 받아 데이터베이스나 데이터 웨어하우스에 데이터를 투입하여 BI 도구를 사용하거나 액세스 해석 전용 도구나 서비스를 이용해 작업하는 경우가 대부분이다. 이때 외부에서 제공하는 서비스를 쓰지 않고 자신이 직접 로그 분석 환경을 만드는 경우 위의 데이터 허브나 로그 수집에서 언급한 환경을 구축하게 된다. 이것은 배치처리적 분석 환경 구축이라고 볼 수 있다.

그러나 배치 처리적인 접근 다음 단계에서는 사용자의 행동을 실시간으로 파악해 즉시 대응하려는 요구가 분명히 나타난다. 전형적인 예는 다음과 같다.

- 상태 업데이트가 시시각각 표시되는 실시간 대시보드 구축
- 실시간 이상 탐지/부정 검출
- 실시간으로 사용자의 행동을 추적하여 서비스 이탈 방지

링크드인이 웹 활동 분석으로 실현하고 싶은 것은 여러 가지이지만 여기에서는 실시간 웹 활동 분석에 초점을 두고 이를 카프카로 구현하는 점을 생각해보기로 한다.

### 5.5.2 웹 활동 분석에서 해결해야 할 과제

실시간으로 웹 활동을 분석하는 데 있어 고려해야 할 과제의 대표적인 내용은 다음과 같다.

**'실시간'을 실현하기 위한 구조**

긴급성과 즉시성을 필요로 하기 때문에 이를 실현하기 위한 구조가 필요하다. 실시간으로 데이터를 받으려면 어떻게 하면 좋을지, 데이터 파이프라인 내부 어디에서 실시간 처리할 것인지, 이를 위해 어떤 제품을 사용할지에 대한 검토가 필요하다. 또한 레코드 단위로 작업을 해야하는지, 수 밀리초 시간폭으로 여러 레코드 단위로 처리해도 상관없는지 같은 여러 요구 사항도 확인해야 한다.

**여러 데이터 소스와 접속**

데이터를 생성하는 쪽 시스템이 여럿 있을 경우 해당 시스템들과 접속할 수 있어야 한다. 데이터 허브나 로그 수집이 갖고 있는 과제와 동일하다.

**데이터 분실 방지**

예를 들어 이상 탐지, 부정 검출을 해야하는데 데이터 레코드가 손실됐을 경우 확인할 방법이 없다. 따라서 레코드를 잃지 않기 위한 송시신 보증이 필요하다. 단, 웹 서비스의 경우 중복 없이 1건 송신하는 것을 엄격하게 요구하는 경우는 그리 많지 않다고 생각한다. 왜냐하면 Exactly Once(중복 및 손실 없이 1회만 송수신)라고 하면 데이터 처리량이 감소하고, 구현이 복잡해지는 경향이 있기 때문이다. 따라서 대량의 데이터를 처리해야 하는 경우 엄밀한 송수신 보증은 보류하고, 데이터 분실은 허용하지 않지만 데이터 중복은 최소 허용(At Least Once)하는 수준으로 하는 경우가 많다.

**순서 보증**

순서 보증의 경우 온라인 게임에서 사용자 이탈 방지 사례가 이해하기 쉬울 것 같다. 게임을 즐기는 사용자의 동작을 추적한 데이터는 서비스 개선에 활용할 수 있을 뿐만 아니라 사용자가 현재 어떤 상황에 있는지도 분석할 수 있다. 데이터를 잘 활용하면 사용자가 실증난 상태를 감지할 수 있다는 의미다. 사용자가 게임에 실증난 상태를 그대로 방치하면 사용자는 떠나게 되고 다시는 게임을 찾지 않을지도 모른다.

그래서 실증난 상태를 감지하면서 즉시 특별 이벤트를 실시하거나 귀중한 아이템을 주는 등 사용자의 이탈 방지를 막을 수 있다. 이때 '사용자가 현재 어떤 상황에 있는지'를 파악하는 아이디어로 사용자의 행동 순서를 고려하는 방법이 있다. 그렇기 때문에 사용자 행동 순서대로 데이터를 받기 위한 장치가 필요하다.

### 5.5.3 카프카로 웹 활동 분석하기

위의 문제에 대해 카프카에는 '실시간', '다수의 연계 제품', '송수신 보장', '순서 보증'의 기능이 있어 유효하다.

실시간으로 처리하는 부분은 Kafka Streams를 이용하는 방법도 있고, 카프카 뒤에서 스파크의 스트림 처리를 위한 구성 요소인 Structured Streaming을 사용하는 방법도 있다.

실시간 발생하는 데이터를 간헐적으로 수신하고, 수신한 데이터를 바로 처리하기 때문에 이른바 **스트림 처리**가 가능하다. 다만 스트림 처리는 배치 처리 시스템을 구축하는 것과는 다른 어려움이 있다.

---

### 스트림 처리란?

스트림 처리는 실시간 생성되는 데이터를 순차적으로 처리하는 방식이다. 실시간 생성되는 데이터를 **스트림 데이터**라고 부르기도 한다.

스트림 데이터의 예로 시스템 로그나 웹사이트의 클릭 로그, 디바이스에서 생성되는 센서 데이터 등을 들 수 있다. 스트림 데이터의 경우 생성된 데이터가 모여 이루어진 파일 형태로 일정 기간마다 보내는 것이 아니라 킬로바이트 정보의 작은 단위로 지속적으로 보낸다.

스트림으로 데이터를 받아 처리하는 기반을 구현하려면 일단 데이터를 축적하는 배치 처리에 비해 고려 사항이 많아 난이도가 높다. 왜냐하면 지속적으로 데이터를 수신하여 처리해야하므로 시스템 운용을 제약하지 않는 한 처리의 정지점을 마련하는 것이 어렵기 때문이다.

정지점이 없다는 것은 시스템 운용에 많은 부분 영향을 미친다. 시스템 구성 변경 등 유지보수하는 시점이 없는 가운데 어떤 곳에 문제가 발생하면 이는 시스템 전체에 영향을 미친다. 문제가 발생했을 때 해당 처리를 재실행하고자 해도 적절한 시기에 끼워넣기 어렵다는 점도 감안해야 한다. 그 밖에 다음과 같은 사항도 검토해야 한다.

- 데이터의 취득원과 송신처를 늘리는 등 운용 중 설계 변경하기
- 버스트 트래픽이 발생하는 경우에도 가능한 한 장애 없이 탄력적으로 동작하기
- 비정상적인 동작 시 재처리 대응하기

참고로 카프카 아키택쳐와 카프카가 지닌 특징은 스트림 처리를 실현하기 위한 과제의 일부를 해결할 수 있다.

---

## 5.6 사물인터넷

여기서는 사례 중 하나인 사물인터넷에 대해 살펴본다.

### 5.6.1 사물인터넷으로 실현하고자 하는 것

사물인터넷이란 통신 기능이 있는 다양한 디바이스가 인터넷을 통해 서로 연결되어 있는 상태를 말한다. 센서나 통신 기기의 소형화, 저전력화에 따라 다양한 디바이스가 인터넷에 접속할 수 있게 됐다. 그리고 그런 디바이스에서 발생하는 대량의 데이터를 비교적 저렴하고 안정적으로 보관할 수 있는 하둡과 클라우드 환경을 이용할 수 있게 된 것이 그 등장 배경이기도 하다.

다양한 디바이스가 인터넷을 통해 연결되어 있어서 모든 디바이스에서 정보를 수집해 디바이스를 관리하거나 모니터링할 수 있게 되었다. 사물인터넷은 이제껏 취득할 수 없었던 데이터를 수집하고 활용할 수 있게 되었으므로 사회에 변혁을 가져올 가능성을 내재하고 있어 많은 주목을 받고 있다.

사물인터넷 이용 사례로 다음과 같은 것을 들 수 있다.

- 디바이스 모니터링<br>
  개별 디바이스에서 정보를 직접 수집하고 디바이스 상태를 파악한다. 측정 미터의 값을 육안으로 확인하던 기존의 모니터링 작업을 대체한다.
- 예방 보전, 예측 보전/사전 감지<br>
  디바이스의 상태를 시계열로 수집하고 수집한 데이터를 분석하여 디바이스 고장을 사전에 파악해 고장 전에 교환한다.
- 품질 개선<br>
  디바이스 모니터링을 실시해 시간 경과에 대한 성능 저하를 파악한 후 이를 제품 개발에 피드백하여 품질을 개선한다.
- 원격 제어<br>
  디바이스에서 얻은 정보를 바탕으로 디바이스에 피드백함으로써 디바이스 동작을 원격으로 제어한다.

### 5.6.2 사물인터넷을 실현하기 위한 과제와 카프카 대응

사물인터넷에 있어 큰 과제라면 매 순간 대량으로 발생하는 데이터를 어떻게 처리할 것인가 하는 점이다. 또한 실시간으로 데이터를 교환하는 것과 여러 디바이스와 접속하는 것 두가지도 중요한 과제다. 원격 제어처럼 상태에 따라 즉시 실행을 요구하는 상황에서는 디바이스 데이터를 실시간으로 수집할 뿐만 아니라 해당 요구에 실시간으로 처리한 후 전달하는 구조가 필요하다. 사물인터넷에서는 여러 종류의 디바이스가 연결되어 있으므로 접속을 위한 인터페이스가 알기 쉬워야한다. 특히, 사물인터넷은 MQTT라고 불리는 프로토콜로 전송되는 경우가 많아서 이 프로토콜에 대한 대응도 고려해야 하는 지점 중 하나다.

사물인터넷을 실현하는 데 있어 해결해야 할 과제와 카프카를 이용하여 이를 어떻게 실현할지에 대해서는 10장에서 소개한다.

## 5.7 이벤트 소싱

이 절에서는 사례 중 하나인 이벤트 소싱에 대해서 살펴본다.

### 5.7.1 이벤트 소싱이란?

이벤트 소싱은 상태의 변화 하나하나를 이벤트로 취급하여 발생하는 이벤트를 순서대로 기록해두는 것이다. 사용자는 기록된 이벤트에서 도메인 객체를 구체화할 수 있으며 경위도 확인할 수 있다. 이를 알기 쉽게 설명하면 DBMS의 트랜잭션 로그(WAL:Write Ahead Log)의 레코드 쓰기를 상상하면 좋을 것이다. 카프카는 데이터를 모두 추상적인 '로그'로 취급하고, 받은 메시지는 로그에 순차적으로 기록되기 때문에 카프카의 아키텍쳐 그 자체가 이벤트 소싱에 적합하다는 것을 알 수 있다. 또한 이벤트 소싱과 더불어 이해해야 하는 개념이 CQRS다.

### 5.7.2 CQRS란?

CQRS(Command Query Responsibility Segregation:커맨드 쿼리 책임 분리)란 데이터의 갱신과 문의 처리를 분리하는 개념의 아키텍쳐다.

커맨드(Command)란 데이터의 create/update/delete 등 데이터 갱신 처리에 해단한다. 쿼리(Query)란 데이터 문의, 즉 참조 처리에 해당한다. CQRS Command(갱신)와 Query(참조)의 책임을 분리한다는 의미다. 커맨드 쪽인 갱신 처리는 데이터가 갱신되는 것에만 책임지고 처리한다. 갱신 처리 시 참조 결과에 대해서는 반환하지 않으며 그 데이터가 어떻게 참조되는지에 대해서도 관여하지 않는다. 한편 쿼리 쪽인 참조 처리는 적절한 결과를 반환하는 책임만 있다. 이벤트 소싱과 CQRS 조합에 대해 여기서는 아키텍쳐 측면에서 살펴보기로 한다.

### 5.7.3 이벤트 소싱과 CQRS로 해결해야 할 과제

제공하는 서비스 특성에 따라 애플리케이션에서 기록할 때와 읽을 때의 액세스 패턴이 크게 다를 수 있다. 대량의 데이터가 시계열로 기록되어도 읽을 때는 시계열이 아니라 특정 ID 단위로 받고 싶은 경우도 있을 수 있다.

또한 기록되는 데이터는 동일하더라도 그 데이터를 여러 목적으로 사용하고 싶은 경우도 있다. 예를 들어 축적된 데이터를 집계하는 단위가 목적마다 다른 경우가 있다. 기존 BI 시스템 중에서도 데이터 웨어하우스에서 목적별 데이터 마트를 여럿 만들어 각 데이터 마트에서 리포팅을 실시하는 경우가 종종 있다.

만약 데이터 처리의 부하가 높지 않다면 1대의 DB 서버 안에서 쓰기 전용과 읽기 전용의 테이블을 2개 준비해서 테이블의 형식을 변환하는 방법도 생각할 수 있다. 그러나 쓰기와 읽기 모두 처리 부하가 높은 경우에는 성능을 높이기 위한 튜닝의 난이도가 높아진다. 이를테면 메모리 사용법에 있어 쓰기 전용 버퍼 공간을 많이 확보할 것인지 아니면 읽기 전용 캐시로 공간을 많이 확보할지 메모리 사용을 어떻게 해야 할지 망설이게 된다.

이처럼 1대의 DB 서버에서는 쓰기와 읽기를 효율적으로 구현할 수 없는 상황이 생길 수 있는데, 이때 등장하는 것이 데이터 쓰기와 읽기를 분리하는 CQRS 개념이다.

### 5.7.4 이벤트 소싱 + CQRS에 카프카 사용하기

CQRS 개념인 갱신처리와 참조 처리의 분리를 위해 카프카를 아키텍쳐로 사용한다. 카프카는 이벤트를 저장하는 저장소이며 이벤트를 전달하는 허브로 간주할 수 있다. CQRS는 다음과 같은 형태로 구현한다.

- 카프카가 데이터 소스에서 시계열 데이터를 받아 기록한다. 이것은 커맨드 쪽 역할을 한다.
- 카프카가 데이터 싱크에 데이터를 전달한다. 받은 쪽은 자신의 쿼리에 있어서 참조 효율이 좋은 형식으로 데이터를 변환하여 사용한다.
- 이렇게 해서 커맨드와 쿼리의 분리가 가능해진다.

예를 들면 카프카는 커맨드에 해당하는 개신 처리로 이벤트를 받는 역할을 한다. 쿼리에 해당하는 참조를 처리하기 위한 형식 변환은 카프카와 분리된 별도 기반에서 담당한다. 게다가 참조를 위한 DBMS를 뒤편에 준비해 카프카와 분리했다. 이때 카프카는 커맨드(갱신처리)의 순차 기록과 데이터 허브로서 데이터를 전달하는 두 가지 역할을 담당한다. 또한 읽기와 쓰기 처리를 분리만 하는 것이 아니라 읽기 형식이 여럿이거나 여러 시스템이 존재하는 등 다양한 요구 사항에도 대응이 가능하다.

이렇듯 이벤트 소싱과 CQRS 개념을 조합함으로써 애플리케이션에서 쓰기와 읽기 액세스 패턴이 다르더라도 유연하게 대응할 수 있다. 이벤트를 여러 용도로 사용하는 경우에도 각각의 요구 사항에 적합한 데이터 모델을 적용할 수 있다.

## 5.8 카프카 활용 사례

이 절에서는 공개된 카프카 활용 사례 중 일부를 소개한다. 지금까지 언급한 카프카의 기능과 특징이 조합된 형태로 이용되고 있음을 알 수 있다.

### 5.8.1 우버

2016년 공개도니 미국 우버의 스트림 처리 사례를 소개한다. 방대한 양의 데이터를 처리하는 실시간 배치 처리에서 모든 대응을 고려한 데이터 허브/로그 수집/웹 활동 분서 사례다.

우버는 자동차 배차 서비스를 하는 기업이다. 배차 서비스를 하려면 실시간 처리를 빼놓을 수 없다. 사업 성장을 위해 수신한 데이터가 실시간이든 애드혹이득 그 방식을 불문하고 데이터를 다양한 분석에 활용할 필요가 있다. 취급하는 데이터 양은 초당 100,000 이벤트에 이르며 데이터의 분실은 허용하지 않는다. 우버가 실시간으로 분석하는 대표적인 예로 다음과 같은 것이 있다.

- 빈 차가 현재 몇 대 있는지
- 지난 10분간 몇 대의 차가 승객을 태웠는지
- 지난 10분 이내에 3회 이상 운전자의 취소가 몇 번이었는지

이러한 사항은 우버 서비스 향상에 직결되는 내용이다. 아래의 경우는 실현한 것으로 알려져 있다.

- 차량의 위치 정보 시각화
- 운반한 승객 수를 지도에 색으로 표시

또한 애드혹 분석에도 대응할 수 있어 BI 도구나 하둡을 이용해 카프카로부터 데이터를 취득하는 아키텍처를 구성했다.

### 5.8.2 ChatWork

2017년 공개된 ChatWork를 통해 이벤트 소싱+CQRS 사례를 살펴보자. ChatWork는 세계적으로 사용하는 커뮤니케이션 서비스로 현재 11만명 이상의 고객을 보유하고 있다. ChatWork의 경우 급성장하는 웹 서비스의 이벤트 처리 일부에 카프카를 사용했다. 시스템 도입에 있어 NTT데이터가 지원한 사례 중 하나다.

이 사례에서는 다음 두 가지 요구 사항을 목표로 했다.

- 데이터 생성과 연계에 관한 이벤트를 처리한다.
- 향후 이용자 증가에 대비하여 처리량을 늘릴 수 있도록 한다.

취급하는 데이터 양은 1분당 약 4,000 이벤트이며 메시지 크기는 최대 400바이트다. 연간 2배씩 처리 건수가 증가하고 있어 확장성을 확보하는 것이 급선무였다. 이 사례에서도 데이터 분실은 허용하지 않는 상황이었다.

ChatWork 커뮤니케이션 서비스는 일본을 포함한 글로벌 서비스이며 늘어나는 데이터를 실시간으로 처리해야만 했다. 이것은 비지니스에 필수적인 커뮤니케이션 비비스로 사용자 만족도와 직결되는 아주 중요한 문제였다.

이 사례의 요구 사항을 구현하는데 있어서 시스템 분석가들은 액세스 패턴에 주목했다. 발생한 이벤트가 시계열로 기록되는 한편 이벤트로부터 변환된 데이터 모델을 읽을 때는 내부에서 사용하는 ID를 토대로 읽고 있었다. 서비스 특성상 최근 데이터를 중점적으로 읽는 한편, 특정 ID나 특정 범위에 대한 액세스도 발생하기 때문에 읽기와 쓰기에서 데이터 조작 패턴이 달랐다.

그러한 이유로 이벤트 소싱과 CQRS 개념에 기초해 데이터를 읽고 쓰는 것을 분리하는 기반을 채택하게 된다.

이벤트 수신 기반으로는 대량의 데이터를 처리할 수 있고 스케일 아웃에 의한 성능 향상이 가능한 카프카를 이용하고 있다. 카프카가 펍/섭 메시징 모델에 기초하고 있음을 활용했기 때문에 이 사례의 경우는 향후에도 서비스를 추가하기 쉽다. 커맨드 쪽에서 쿼리 쪽으로의 변환에는 Akka와 Kafka Streams를 이용했다. 또한 이벤트를 참조할 때 사용되는 DB도 확장성을 요구하고 있었기 때문에 여기에서는 HBase를 채택했다. 이 사례에서는 카프카를 이용하여 대량의 이벤트를 손실 없이 빠르게 처리하는 기반을 실현했고, 카프카와 확장 가능한 DB를 연계해서 미래의 성능 향상도 가능하게 했다.

### 5.8.3 Yelp

마지막으로 카프카 서밋 런던 2018에서 공개된 Yelp에서는 데이터 허브의 사례를 볼 수 있다. 실시간과 배치 처리라는 두 가지 대응을 지원하는 데이터 허브/로그 수집 사례인데 스키마 관리 부분에 특징이 있다.

Yelp는 여러 서비스를 하고 있으며, 각 서비스에서 수집하는 데이터를 여러 팀에서 활용하고 있다. 이와 관련된 엔지니어만 500명 이상이다.

Yelp에서 구축한 데이터 파이프라인에서는 데이터 허브로 카프카를 이용하고 있다. 데이터 소스로는 MySQL, 카산드라, Yelp의 메인 사이트, 그 외 데이터 저장소나 서비스가 있다. 데이터 싱크에는 MySQL과 Memchached, Elasticsearch가 있다. 이외에도 데이터 레이크로 S3와 Parquet를 준비하고 있으며 거기에 접속하는 형태로 Amazon Redshift, Amazon Athena, Apache Spark를 이용한다.

데이터 소스에서 생성된 데이터는 카프카로 받아 스트림 처리한다. 스트림 처리는 자바/스칼라/파이썬으로 구현하는 것 외에 Apache Flink나 Yelp가 독자적으로 개발한 Paastorm이라는 스트림 처리 기반을 이용한다. 스트림 처리된 데이터는 다시 카프카에서 받아 데이터 싱크에 전달한다.

Yelp 데이터 허브 사례에서 특징은 독자적인 데이터 관리를 구현한 것이다. Yelp는 많은 이용자가 데이터를 자율적으로 이용하기 위해서는 데이터의 정렬, 즉 데이터가 정리된 상태여야 한다고 주장한다. 실제로 데이터를 이용하고 싶어도 어디에 어떤 데이터가 있는지 몰라 난감했던 경험을 한 사람이 많을 것이다.

이러한 정렬을 실현하기 위해서는 어떤 스키마에 어떤 칼럼이 포함되어 있는지를 관리하는 데이터 사전이 필요하다. 또한 어떤 데이터에 대해 데이터 파이프라인에서 어떤 데이터와 어떤 데이터를 결합하여 만들었는지를 찾는 데이터 리니지도 필요하다. 이러한 개념은 데이터 관리의 세계에서는 예전부터 필요했던 것인데 적절한 상태를 유지하려면 그에 상응하는 비용이 들 수 있다.

Yelp에서도 스키마 참조를 스프레드 시트로 관리하던 것에서 카프카를 이용한 데이터 허브로 바꾸면서 보다 효율적인 데이터 거버넌스 구조를 구현했다.

필요한 도구 중 하나로 데이터 소스 쪽에서 스키마 변경을 제대로 따라갈 수 있도록 카프카의 스키마 레지스트리 구조를 도입했다. 스키마 레지스트리에 의해 스키마 변경에 따라 후속 데이터의 상태가 올바르지 않음을 기계적으로 방지할 수 있다.

이외에도 자체적으로 데이터 사용에 있어 필요한 정보를 정리하고 데이터 파이프라인 전체 상태를 시각화하고 있다. Yelp 프레젠테이션에 의하면 이외에도 자체적으로 아래 4가지 사항으로 데이터 사용에 있어 필요한 정보를 정리하고 데이터 파이프라인 전체 상태를 시각화하고 있다.

- 이 칼럼의 의미는?<br>
  \- 문서화, 소유권 명확화
- 어떤 데이터를 사용할 수 있나? 어떤 데이터를 사용해야 하나?<br>
  \- 왓슨과 태그를 통한 데이터의 큐레이션(데이터 사전의 정보를 웹에 제공해 검색을 가능하게 함)
- 이 데이터는 정확한가?<br>
  \- 이 데이터는 어디에서 온 것인가? -> 데이터 리니지와 컨수머/프로듀서 등록(스키마 레지스트리 이외에도 컨수머/프로두서 자체를 관리하는 구조를 도입)
  \- 모든 구성 요소가 제대로 작동하고 있는지? -> Data Auditing(데이터 소스와 데이터 싱크를 연결하는 경로에 있는 구성 요소의 동작 상황을 감시해 웹에 그리기)
  \- 이 데이터가 최신인가? -> 이벤트 발생 시간 및 오프셋 모니터링 (모든 레코드에 시각을 부여하고 데이터의 갱신 상황을 DAG 형식으로 가시화)
- 어떻게 하면 그 데이터를 사용할 수 있는지?<br>
  \- Declarative Data Connections(대화식 CLI를 준비해 필요한 스키마 및 옵션을 선택함으로써 원하는 데이터를 얻을 수 있는 구조를 도입)

데이터 관리의 실현은 종종 업무적인 의미의 이해도 필요해 비용이 많이 든다. 데이터 소스와 데이터 싱크에서 스키마가 일치하지 않을 때의 문제점에 대해서는 6장에서 설명하고 있다.

여기에서 언급한 Yelp는 데이터 허브로 카프카를 사용하고, 카프카의 기능을 활용하면서 다양한 사용자 액세스를 위해 철저한 데이터의 시각화/유지 관리 자동화를 실현한 예라고 할 수 있다.

## 5.9 정리

이 장에서는 카프카의 대표적인 기능 데이터 허브, 로그 수집, 웹 활동 분석, 사물인터넷, 이벤트 소싱에 대해 알아봤고 카프카에서 어떻게 구현하는지 설명했다. 또한 공개된 사례를 소개하고 5가지 기능이 실제로 서로 조합되서 사용되고 있음을 설명했다.

이를 통해 카프카를 어떤 상황에서 사용하면 좋은지 다소나마 이해할 수 있으리라 생각한다. 대량의 데이터를 전달하거나 처리하는 상황에서 카프카를 이용하게 되는데 그 이용 목적이 무엇인지를 하나하나 세부적으로 생각하는 계기가 되었으면 한다.
