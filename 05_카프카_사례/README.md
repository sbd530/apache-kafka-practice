# 5장 카프카 사례

## 5.1 이 장의 내용

5장에선는 카프카 적용 사례를 소개한다. 카프카의 특징을 복습하면서 예로 든 사례에 카프카가 적합한 이유를 설명한다. 공개된 사례로 카프카가 실제 어떻게 이용되는지를 알아보자.

## 5.2 카프카 적용 사례

1장에서 소개한 대로 카프카는 미국 링크드인이 자사의 웹사이트를 방문하는 사용자의 호라동을 추적하기 위한 목적으로 개발했다. 당시 다른 제품에서는 할 수 없었던 것을 카프카로는 실현할 수 있었고, 카프카에 더 많은 기능이 추가되면서 카프카 적용 사례도 퍼져나가게 되었다. 먼저 카프카 사례부터 소개한다.

### 5.2.1 카프카의 대표적 기능

카프카의 대표적인 기능으로 떠올릴 수 있는 것은 메시지 큐 제품/로그 수집 제품/ETL 도구 등 예전부터 존재했던 몇몇 제품의 대체라고 할 수 있다. 대부분 '이전 제품에서는 더이상 취급하지 못할 정도로 대량의 데이터를 처리해야 할 때' 카프카를 검토했다고 생각하면 될 것이다.

여기서는 구체적으로 알 수 있도록 실제 사용 현장에서 카프카가 어떤 상황에서 사용되는지 살펴본다. 1장에서 언급한 바와 같이 카프카는 단순하면서도 유연한 아키텍처라서 다양하게 사용된다. 우선 카프카의 대표적 기능 5가지부터 알아보자.

- 데이터 허브<br>
  여러 시스템 사이에서 데이터를 상호 교환한다.

- 로그 수집<br>
  BI 도구를 이용한 리포팅과 인공지능 분석을 위해 여러 서버에서 생성된 로그를 수집하고 축적할 곳에 연결한다.

- 웹 활동 분석<br>
  실시간 대시보드와 이상 탐지/부정 검출 등 웹에서의 사용자 활동을 실시간으로 파악한다.

- 사물인터넷<br>
  센서 등 다양한 디바이스에서 보낸 데이터를 수신해서 처리한 후 디바이스에 송신한다.

- 이벤트 소싱<br>
  데이터에 대한 일련의 이벤트를 순차적으로 기록하고 CQRS 방식으로 대량의 이벤트를 유연하게 처리한다.

물론 여깃서 열거한 모든 기능과 특징을 전부 사용하는 경우는 드물다. 특정 기능이 어떤 사례에서는 중요하더라도 그것이 반드시 다른 사례에서도 중요시 된다고는 말할 수 없다. 카프카는 유연한 구조로 되어 있어서 각 사례마다 다른 요구 사항을 토대로 기능을 취사 선택하거나 또는 요구 사항에 맞게 설정해서 사용하는 경우가 많다.

### 5.2.2 카프카 특징 복습

카프카는 대량의 데이터를 '높은 처리량'으로 '실시간' 처리하기 위한 제품이다. 카프카가 링크드인에서 탄생했을 때부터 현재에 이르기까지 카프카의 아키텍처는 변함없이 데이터 상호 교환을 위한 기반으로 발전해왔다. 현재는 카프카가 데이터를 전달하는 **파이프라인** 그 자체를 구성하기 위한 기반이라고 말할 정도다. 다시 한 번 카프카로 실현할 수 있는 4가지를 살펴보자.

- 확장성 : 여러 서버로 확장(스케일 아웃) 구성할 수 있기 때문에 데이터 양에 따라 시스템 확장이 가능하다.
- 영속성 : 수신한 데이터를 '디스크에 유지'할 수 있기 때문에 언제라도 데이터를 읽을 수 있다.
- 유연성 : '연계할 수 있는 제품이 많기' 때문에 제품이나 시스템을 연결하는 허브 역할을 한다.
- 신뢰성 : '메시지 전달 보등'을 하므로 데이터 분실을 걱정하기 않아도 된다.

또한 데이터를 주고받을 뿐만 아니라 카프카의 기능과 다ㅏ른 제품을 결합함으로써 실시간으로 높은 처리량의 데이터를 처리할 수 있다. 따라서 간헐적으로 발생하는 데이터를 수신하여 그때마다 순차 처리하는 **스트림 처리**의 기반으로 카프카를 사용할 수 있다.

카프카는 위의 4가지를 실현하기 위한 아키텍쳐로 펍/섭 메시징 모델 기반이라는 점도 설명했다. 이에 따라 메시지 큐 모델과는 달리 동일한 메시시를 여러 곳에 전달하는, 이른바 **동보 전송**도 가능하다. 또한 2장에서도 다루었듯이 메시지를 토픽에 포함된 파티션 단위로 한정하면 메시지의 순서보증의 실현 또한 가능하다.

이러한 사항을 바탕으로 대량의 데이터를 처리해야 하는 전제하에, 카프카의 각 지응과 특징이 중시되는 상황을 정리하면 다음과 같다.

- 실시간<br>
  \- 긴급성이 요구되거나ㅏ 데이터를 즉시 사용하는 경우
- 동보 전송<br>
  \- 하나의 동일한 데이터를 후속의 여러 시스템에서 사용하는 경우. 데이터를 전달하는 관계 시스템이 단계적으로 증가하는 경우
- 영속성<br>
  \- 데이터를 버퍼링해야 하는 경우나 처리 시간 간격이 다른 복수의 처리와 관련된 경우
- 다수의 제휴 제품<br>
  \- 사용되는 제품이 균일하지 않고 다양한 접속을 필요로 하는 경우
- 송수신 제품<br>
  \- 데이터 손실이 허용되지 않는 경우
- 순서 보증<br>
  \- 데이터 소스에 있어 데이터의 생성 순서를 중시하여 순서에 따른 판단과 제어를 수반하는 경우

### 5.2.3 카프카 특징과 사례 대응

카프카의 기능과 특징을 앞서 언급한 5가지 사례에 맞춰 보았다. 표에서는 각 사례에서 중요시하는 항복에 O 표기했다. 원래 링크드인에서의 용도는 데이터 허브, 로그 수집, 웹 활동 분석 3가지를 합친 것이어서 모든 항목에 O가 있지만 여기에서는 이해하기 쉽게 분리해서 다룬다.

| 사례         | 실시간 | 동보 전송 | 영속성 | 다수의 제휴 제품 | 송수신 보증 | 순서 보증 |
| ------------ | ------ | --------- | ------ | ---------------- | ----------- | --------- |
| 데이터허브   |        | O         | O      | O                | O           |
| 로그 수집    |        |           | O      | O                | O           |
| 웹 활동 분석 | O      |           |        | O                | O           | O         |
| 사물 인터넷  | O      |           |        | O                |             |
| 이벤트 소싱  | O      |           | O      |                  | O           | O         |

## 5.3 데이터 허브

이 절에서는 사례 중 하나인 데이터 허브를 살펴본다 .여기서 데이터 허브란 여러 곳의 데이터소스가 되는 시스템에서 데이터를 수집하여 여러 시스템에 전달하는 아키텍처를 의미한다.

### 5.3.1 데이터 허브로 실현하고자 하는 것

비지니스에 있어서 IT 시스템은 IT 전문 기업뿐만 아니라 일반 기업에서도 많이 사용한다. 특히 사업 부문별로 업무 시스템화를 추진한 조직에는 부서마다 개별 시스템이 있는데, 이러한 개별 시스템은 각각 독립적으로 최적화되어 운용되는 경우가 많다. 이렇게 독립적으로 존재하는 시스템 사이에서는 효율적인 데이터 전달이 필요하다.

### 5.3.2 데이터 허브에서 해결해야 할 과제

데이터 허브가 없는 경우 어떤 문제가 있을지 생각해보자. 독립된 시스템이 많은 회사는 시스템 간 데이터 연계라는 큰 과제가 있다. 잠깐 생각하더라도 다음과 같은 사항을 고려해야 할 것이다.

- 데이터 형식은 CSV로 좋은지
- 송신 타이밍은 1일 1회로 좋은지
- 상대 시스템이 유지보수하는 동안 어떻게 할 것인지
- 장애가 발생했을 때 데이터를 잃지 않기 위해서 어떻게 할지

예를 들어 시스템에 있는 데이터를 다른 3개의 시스템으로 전송해야하는 경우 3개의 시스템별로 데이터 연계 방식을 조정해야한다. 이러한 것을 시스템 특성을 고려하여 조정하려면 상당한 노력이 필요하다.

게다가 1년 후에는 연계 시스템이 늘어날 수도 있다.

이 경우 앞서 실시했던 연계 시스템 간의 조정을 늘어난 시스템에도 적용하고 현재 문제없이 동작하고 있는 시스템에도 수정을 거쳐 안정적으로 가동시켜야 한다. 시스템이 많으면 많을수록 시스템 간의 접속 패턴과 변형이 많아져서 좀처럼 수습하기가 어렵다.

이처럼 시스템이 분리되어 시스템 간의 연계를 효율적으로 할 수 없는 상황을 사일로(silo)화됐다고 한다. 사일로화된 시스템은 IT 기술의 보급과 함께 전 세계적으로 많이 발생했다. 그리고 사일로화에 의한 문제를 해결하기 위한 솔루션도 많이 개발됐다. 시스템 사일로화에 의한 접속 수 증가에 따라 다음과 같은 과제를 해결해야 한다.

- 데이터 소스에서 생성된 동일한 데이터를 여러 시스템에서 이용한다.
- 후속 시스템마다 데이터를 필요로 하는 시기와 빈도가 다르다.
- 접속원이나 연결 시스템에서 이용되는 연계 방식이 제각각이다.(예: FTP 전송에 의한 파일 연계 규칙이 시스템마다 다르거나, JDBC 접속으로 연결되는 DBMS 제품이 여러 종류인 경우)
- 데이터 분실을 허용하지 않는다.

### 5.3.3 카프카로 데이터 허브 구현하기

사일로화를 해결하기 위한 개념의 하나로 데이터 허브 아키텍처가 있다. 데이터 허브 아키텍처란 데이터 소스가 되는 시스템에서 데이터를 수집하여 해당 데이터를 여러 시스템에 전달하는 아키텍처다.

데이터 허브 아키텍처에서는 시스템을 일대일로 연결하는 대신 모든 시스템이 데이터 허브에 데이터를 보내고 데이터 허브에서만 데이터를 받을 수 있도록 되어 있다. 이렇게 하면 시스템은 데이터를 데이터 허브에 보내는 것만 생각하면 되고, 데이터를 수신하는 시스템도 데이터 허브에서 데이터를 받는 것만 생각하면 된다. 카프카를 데이터 허브로 이용함으로써 다대다(M:N) 접속을 '모든 시스템은 카프카에 연결하기만 하면 된다'는 형태로 해결할 수 있다. 그 외의 과제도 카프카에서는 해결 가능하다.

- 동보 전송<br>
  \- 데이터 소스에서 생성된 동일 데이터를 여러 시스템에서 이용할 수 있다. 이는 펍/섭 메시징 모델로 착안했기 때문에 실현가능하다.
- 영속화<br>
  \- 데이터를 필요로 하는 시기와 빈도가 후속 시스템마다 다른 문제에 대해 카프카는 데이터를 영속화하고 버퍼링함으로써 임의의 시기에 추출할 수 있다.
- 다수의 연계 제품<br>
  \- Kafka Connect로 연계할 수 있는 제품이 다수 있기 때문에 접속원이나 연결 시스템에서 사용하는 제품이 다수라고 하더라도 이에 대응할 수 있는 가능성이 높다.
- 송수신 보증<br>
  \- 카프카는 데이터 분실이 허용되지 않는 요구 사항에 대해 송수신을 보증한다. At Least Once, Exactly Once 등 서로 다른 수준의 송수신 보증에도 대응할 수 있다.

이와 더불어 데이터 허브로서 시스템을 중개하려면 '단순히 데이터만 가져오기', '단순히 데이터만 모으기'만을 하는 것이 아니라 여러 시스템에 대해 '사용법에 맞게 사용하기 쉬운 방식으로 데이터를 보관하는 것'도 중요하다.

## 5.4 로그 수집

이 절에서는 사례 중 하나인 로그 수집에 대해 살펴본다.

### 5.4.1 로그 수집으로 실현하고자 하는 것

여러 서버에 존재하는 로그파일을 한 곳에서 보관하고 싶은 경우가 있다. 예를 들면 여러 로그의 결과를 모아서 BI 도구나 대시보드에서 시각화하고 싶은 경우다. 또는 집약한 로그를 이용하여 머신러닝을 구현하고 싶을 수도 있을 것이다. 더 간단하게는 여러 서버의 로그 내용을 확인하는데 그때마다 각 서버에 들어가 확인하는 것이 귀찮은 경우도 있다. 로그 수집을 간단한 것으로 생각할지도 모르겠지만 애플리케이션이 늘어나면서 외부와의 연계가 증가하면 로그 수집을 위한 노력도 증가한다. 이를 보다 편하게 하고 싶다는 생각은 매우 자연스러운 것이다.

### 5.4.2 로그 수집에서 해결해야 할 과제

로그 수집은 우선 여러 데이터 소스와 연결돼야 한다. 데이터 소스로 사용하는 제품이 동일하다면 그 제품에 특화된 것도 괜찮지만 다양한 제품과의 연계를 염두에 둬야 한다.

또한 '일괄적으로 일정 간격마다 축적'하는 것과 함께 '버퍼가 넘쳐 로그를 잃는 일'이 벌어지면 곤란하므로 대량의 로그를 받아 일정한 모음으로 집약하고 버퍼링하기 위한 장치가 필요하다.

마지막으로 로그 전달 시 로그를 잃어서는 안 된다는 점이 있따. 약간의 손실을 허용하는 경우도 있겠으나, 엄격한 트랜잭션 관리까지는 아니더라도 로그가 손실되어서는 안된다는 것이 현실적인 요구 사항이다.

### 5.4.3 카프카로 로그 수집하기

이러한 과제를 해결하는 데 있어 카프카가 유용한 점은 다음과 같다.

**다수의 연계 제품**

카프카에는 Producer API가있어 이를 이용하여 카프카와 접속하는 애플리케이션을 만들 수도 있다. 처음부터 애플리케이션을 작성하는 것이 힘들다면 단순히 서버 로그만을 집계하는 경우 Fluentd를 도입하여 Fluentd와 카프카 조합을 구성하는 것도 좋은 방법이다. 또한 Kafka Connect를 사용하는 경우는 컨플루언트 플랫폼이나 커뮤니티에서 제공되고 있는 여러 커넥터를 이용하여 카프카와 연계할 수 있다.

**영속화**

카프카는 데이터를 디스크에 영속화한다. 메모리 공간보다 더 큰 데이터라면 이를 디스크에 보관해 혹여 메모리 안에서 손실되거나 제외되더라도 나중에 읽을 수 있도록 되어있다. 카프카를 메모리 공간을 넘어서는 큰 용량의 버퍼로 이용할 수 있다는 점이 로그 수집에서 카프카를 이용하는 큰 이유라고 할 수 있다.

**송수신 보증**

링크드인의 사례처럼 At Least Once (적어도 한 번은 보내기) 수준의 송수신은 보증한다. 한편 약간의 손실을 허용하는 경우는 Ack를 반환하지 않음으로써 데이터 소스 쪽의 처리를 줄여 성능 향상을 우선할 수도 있다. 이와 같이 필요에 따라 조정 가능하다는 점도 장점이다.
<br><br>
참고로 로그 수집을 실현한 제품으로는 Scribe, Flume 같은 제품도 있으며 카프카도 이러한 제품을 의식하고 있따. 카프카가 Scribe나 Flume보다 나은 점을 꼽으라면 우수한 성능, 강한 내장애성(복제 가능), 종단 간 지연 시간이 낮은 점 등이다.

## 5.5 웹 활동 분석

사례 중 하나인 웹 활동 분석에 대해 살펴보자.

### 5.5.1 웹활동 분석으로 실현하고자 하는 것

웹 활동 분석을 웹사이트를 방문하는 사용자의 행동을 파악하여 마케팅에 활용하기 위한 작업이다. 사용자가 웹에서 클릭하는 활동은 기본적으로 모두 로그에 남으므로 사용자가 웹사이트의 페이지 사이를 어떤 식으로 이동했는지 파악할 수 있다.

웹 활동 분석의 대표적인 사례는 다음과 같은 것이 있으며, 이를 통해 실현하고 싶은 것 또한 매우 다양하다.

- 페이지 뷰와 전환율(성공율/구매율) 파악
- 개인화된 권장 사항
- 로얄 고객을 파악하는 고객 클러스터링
- A/B 테스트에 의한 웹사이트 개선

웹사이트 액세스 분석에서는 일정량의 로그 모음을 받아 데이터베이스나 데이터 웨어하우스에 데이터를 투입하여 BI 도구를 사용하거나 액세스 해석 전용 도구나 서비스를 이용해 작업하는 경우가 대부분이다. 이때 외부에서 제공하는 서비스를 쓰지 않고 자신이 직접 로그 분석 환경을 만드는 경우 위의 데이터 허브나 로그 수집에서 언급한 환경을 구축하게 된다. 이것은 배치처리적 분석 환경 구축이라고 볼 수 있다.

그러나 배치 처리적인 접근 다음 단계에서는 사용자의 행동을 실시간으로 파악해 즉시 대응하려는 요구가 분명히 나타난다. 전형적인 예는 다음과 같다.

- 상태 업데이트가 시시각각 표시되는 실시간 대시보드 구축
- 실시간 이상 탐지/부정 검출
- 실시간으로 사용자의 행동을 추적하여 서비스 이탈 방지

링크드인이 웹 활동 분석으로 실현하고 싶은 것은 여러 가지이지만 여기에서는 실시간 웹 활동 분석에 초점을 두고 이를 카프카로 구현하는 점을 생각해보기로 한다.

### 5.5.2 웹 활동 분석에서 해결해야 할 과제

실시간으로 웹 활동을 분석하는 데 있어 고려해야 할 과제의 대표적인 내용은 다음과 같다.

**'실시간'을 실현하기 위한 구조**

긴급성과 즉시성을 필요로 하기 때문에 이를 실현하기 위한 구조가 필요하다. 실시간으로 데이터를 받으려면 어떻게 하면 좋을지, 데이터 파이프라인 내부 어디에서 실시간 처리할 것인지, 이를 위해 어떤 제품을 사용할지에 대한 검토가 필요하다. 또한 레코드 단위로 작업을 해야하는지, 수 밀리초 시간폭으로 여러 레코드 단위로 처리해도 상관없는지 같은 여러 요구 사항도 확인해야 한다.

**여러 데이터 소스와 접속**

데이터를 생성하는 쪽 시스템이 여럿 있을 경우 해당 시스템들과 접속할 수 있어야 한다. 데이터 허브나 로그 수집이 갖고 있는 과제와 동일하다.

**데이터 분실 방지**

예를 들어 이상 탐지, 부정 검출을 해야하는데 데이터 레코드가 손실됐을 경우 확인할 방법이 없다. 따라서 레코드를 잃지 않기 위한 송시신 보증이 필요하다. 단, 웹 서비스의 경우 중복 없이 1건 송신하는 것을 엄격하게 요구하는 경우는 그리 많지 않다고 생각한다. 왜냐하면 Exactly Once(중복 및 손실 없이 1회만 송수신)라고 하면 데이터 처리량이 감소하고, 구현이 복잡해지는 경향이 있기 때문이다. 따라서 대량의 데이터를 처리해야 하는 경우 엄밀한 송수신 보증은 보류하고, 데이터 분실은 허용하지 않지만 데이터 중복은 최소 허용(At Least Once)하는 수준으로 하는 경우가 많다.

**순서 보증**

순서 보증의 경우 온라인 게임에서 사용자 이탈 방지 사례가 이해하기 쉬울 것 같다. 게임을 즐기는 사용자의 동작을 추적한 데이터는 서비스 개선에 활용할 수 있을 뿐만 아니라 사용자가 현재 어떤 상황에 있는지도 분석할 수 있다. 데이터를 잘 활용하면 사용자가 실증난 상태를 감지할 수 있다는 의미다. 사용자가 게임에 실증난 상태를 그대로 방치하면 사용자는 떠나게 되고 다시는 게임을 찾지 않을지도 모른다.

그래서 실증난 상태를 감지하면서 즉시 특별 이벤트를 실시하거나 귀중한 아이템을 주는 등 사용자의 이탈 방지를 막을 수 있다. 이때 '사용자가 현재 어떤 상황에 있는지'를 파악하는 아이디어로 사용자의 행동 순서를 고려하는 방법이 있다. 그렇기 때문에 사용자 행동 순서대로 데이터를 받기 위한 장치가 필요하다.

### 5.5.3 카프카로 웹 활동 분석하기
