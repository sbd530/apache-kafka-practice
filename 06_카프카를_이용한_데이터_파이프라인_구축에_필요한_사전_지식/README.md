# 6장 카프카를 이용한 데이터 파이프라인 구축에 필요한 사전 지식

## 6.1 이 장의 내용

5장에서는 실제 사용되고 있는 카프카 사례를 들어 장점과 단점을 소개했다. 이 내용을 근거로 실제로 카프카를 사용할 때 도움이 될 기본적인 몇 가지 예제를 소개한다. 이 장에선느 7장 이후에 등장할 예제를 이해하는 데 필요한 사전 지식에 대해서 소개한다.

## 6.2 카프카를 이용한 데이터 파이프라인의 구성 요소

### 6.2.1 데이터 파이프라인이란?

카프카는 분산 메시징 시스템으로 다른 시스템이나 도구에서 보낸 메시지를 받아 다른 시스템이나 도구의 요청에 근거해 메시지를 전달하는 기능을 제공하고 있다. 시스템 전체에 이르기까지 그 시야를 넓히면 카프카는 데이터의 발생, 수집, 가공, 저장, 출력에 이르는 일련의 과정에서 도구와 시스템을 연결하는 역할을 한다. 이 데이터가 전달되는 경로나 처리를 위한 기반 전체를 '데이터 파이프라인'이라고 한다.

간단한 예로 웹 서비스 사용자 분석을 위한 데이터 파이프라인을 생각해보자. 여기에서는 분석을 위한 정보로 웹 서버의 액세스 로그와 애플리케이션 서버의 애플리케이션 로그를 이용하기로 한다. 이러한 데이터를 장기간 축적하여 집계하고 분석하는 분석 기반과 실시간으로 결과를 출력하는 실시간 집계 기반이 존재한다고 하자. 이때 카프카를 중심으로 하는 데이터 파이프라인과 분석 시스템의 전체 모습은 다음과 같다.

웹 서버 --------(액세스 로그)----------> [카프카 클러스터] -------> 실시간 집계기반

애플리케이션 서버 --(애플리케이션 로그)--> [카프카 클러스터] -------> 장기 보존 & 분석 기반

데이터가 생성되는 웹 서버와 애플리케이션 서버에서 실시간 집계 기반과 분석 기반까지 데이터가 전달되는 경로를 확인할 수 있을 것이다.

2장에서는 카프카가 하나 이상의 브로커로 된 카프카 클러스터, 프로듀서, 컨수머, 카프카 클라이언트로 구성되어 있다고 소개했다. 이 중 데이터 파이프라인의 일부가 되는 것은 카프카 클러스터, 프로듀서, 컨수머다. 앞서 예와 같이 실제 사용에서는 여러 프로듀서와 컨수머가 존재하는 것은 드문 일이 아니다. 이때 프로듀서와 컨수머는 각각 몇 가지 패턴으로 분류할 수 있다. 카프카를 이용하는 시스템의 구성 요소인 프로듀서와 컨수머의 각각의 분류를 살펴보자.

### 6.2.2 데이터 파이프라인의 프로듀서 구성 요소

카프카를 이용한 데이터 파이프라인의 프로듀서 쪽은 데이터를 생성하고 송신하는 미들웨어가 카프카에 대응하고 있는지에 따라 다음의 두 가지 패턴으로 분류할 수 있다.

1. 미들웨어가 직접 카프카에 메시지로 송신하는 패턴
2. 미들웨어가 직접 카프카에 데이터를 송신하지 않고 다른 도구로 메시지를 송신하는 패턴

각각의 패턴에 대해 살펴보자.

#### 1. 직접 카프카에 메시지를 송신하는 패턴

말 그대로 사용하는 미들웨어가 카프카에 메시지를 송신하는 패턴이다. 표준 기능으로 카프카로 송신 기능을 갖추고 있는 것 외에 플러그인 등을 추가함으로써 그 기능을 이용할 수 있는 것도 있다. 이 경우 미들웨어 기능을 이용하여 카프카에 필요한 메시지를 송신할 수 있으므로 비교적 쉽게 카프카로 데잍 파이프라인을 구축할 수 있다.

카프카가 이 분야의 사실상 표준이 된 점도 있기 때문에 최근 카프카로 메시지 송신을 지원하는 미들웨어도 늘고 있다. 예를 들어 병렬 분산 처리 기반의 아파치 하둡(이후 하둡)은 매트릭스 출력기능 중 하나로 카프카에 출력할 수 있다. 또한 병렬 분산 처리 프레임워크인 아파치 스파크(이하 스파크)는 처리 결과를 카프카에 출력할 수 있다.

4장에서 소개한 카프카의 자바 API를 사용하여 데이터를 직접 카프카로 출력하도록 한 애플리케이션도 첫 번째 패턴으로 분류된다. 게다가 카프카는 Kafka Streams라는 스트림 처리를 구현하기 위한 라이브러리그 포함되었는데 Kafka Streams 처리 결과도 기본적으로 카프카에 출력한다. 하둡의 매트릭스와 Kafka Streams를 사용하는 예는 8장에서 소개한다.

#### 2. 직접 카프카에 송신하지 않고 다른 도구로 메시지를 송신하는 패턴

이 패턴은 주로 데이터를 생성하는 미들웨어가 카프카로 메시지를 송신하지 않는 경우에 해당한다. 일단 특정 형식을 데이터를 출력하고, 데이터를 생성하는 미들웨어와는 별개의 메시지 송신 도구를 이용하여 카프카에 전송한다. 또한 미들웨어가 카프카에 대응하는 경우에도 설계상 이유로 직접 송신하지 않고 다른 도구를 사용하는 경우도 있다.

실제로 현업에서 이 패턴을 사용하는 경우도 있다. 이 장 시작 부분에서 소개한 웹 액세스 로그 수집의 경우 일반적인 HTTP 서버는 액세스 로그를 카프카에 직접 송신하는 기능을 갖고 있지 않다. 이 경우는 일단 로컬의 로그 파일에 출력한 뒤 별도의 메시지 송신 도구를 사용해 카프카에 메시지로 송신하는 방식이 일반적이다.

그 밖의 예로 사물인터넷 등에서 센서 장치가 MQTT 프로토콜을 이용하여 데이터를 송신하는 경우가 있다. 이 경우는 데이터를 카프카에 송신하기 위해 프로토콜 변환 목적으로 도구를 사용한다. 이러한 미들웨어가 출력한 데이터를 카프카로 송신하는 도구는 특정 용도에 특화된 것을 포함해 여럿 존재한다. 그중에서도 대표적인 것이 Kafka Connect와 Flunetd다.

Kafka Connect는 카프카 커뮤니티에서 개발한 도구이며 카프카 패키지에 포함되어 있다. Kafka Connect는 외부 데이터를 카프카로 입력하고 카프카에서 외부로 데이터 출력 기능을 제공한다. Kafka Connect를 이용한 예는 7장에서 소개한다. Fluentd는 오픈소스 데이터 수집 도구로 카프카의 메시지 입출력에 특화된 것은 아니지만 각각 입출력용의 플러그인이 제공되고 있다. Kafka Connect에는 커넥터가 준비되어 있고 Fluentd에는 플러그인이 준비되어 있어 이것을 이용해서 데이터를 입출력할 수 있다. 목적에 맞는 커넥터와 플러그인을 이용함으로써 다양한 데이터 형태에 대응할 수 있다.

---

### Kafka REST Proxy

Kafka REST Proxy는 컨플루언트가 오픈소스로 개발하고 있는 카프카의 RESTful API다. 메시지 송수신 및 각종 조작은 카프카 전용 프로토콜로 요청해야 하는데 Kafka REST Proxy를 사용하여 HTTP 프로토콜로 각종 조작이 가능하다. Kafka REST Proxy는 공개된 소스를 빌드하거나 컨플루언트 플랫폼에 포함되어 있는 패키지를 설치하여 사용할 수 있다.

Kafka REST Proxy는 카프카 클러스터와는 별도로 데몬 프로세스로 사용한다. 이 데몬 프로세스가 외부 애플리케이션에서 HTTP 요청을 받고 카프카 클러스터에 카프카 전용 프로토콜로 메시지를 송수신한다. Kafka REST Proxy는 데이터 형태로 JSON, Apache Avro(https://avro.apache.org), 바이너리에 대응하고 있다. 특히 Avro를 이용할 때는 동일하게 컨플루언트가 개발하고 있는 스키마 레지스트리와 연계하여 스키마의 진화(스키마 에롤루션)를 의식한 스키마 관리가 가능하다. 데이터 포맷이나 스키마 에볼루션에 대해서는 6.3절에서 설명한다.

Kafka REST Proxy를 이용하면 여러 프로그래밍 언어에서 쉽게 카프카로 메시지를 송수신할 수 있게 된다. 앞서 이야기한 것처럼 카프카는 전용 프로토콜을 이용하여 통신해야 한다. 자바 API는 제공되고 있지만 그 외 프로그래밍 언어용 라이브러리는 제공되지 않아 타사가 개발한 라이브러리를 사용해야 한다. Kafka REST Proxy는 HTTP통신이 가능한 RESTful API를 사용하기 때문에 많은 프로그래밍 언어에서 쉽게 사용할 수 있다.

네트워크 통신 경로를 이해하기 쉽다는 장점도 있다. 카프카 프로토콜을 사용하여 메시지를 송수신할 때는 프로듀서와 컨수머에서부터 모든 브로커에 통신이 가능해야 한다. Kafka REST Proxy는 HTTP 요청을 받아 카프카에 카프카 프로토콜로 보내고 있다. 따라서 Kafka REST Proxy에서는 모든 브로커와 통신이 가능해야 하지만 HTTP 요청을 하는 애플리케이션에서는 Kafka REST Proxy에만 통신 가능하면 된다. 이에 따라 보안상 이유 등으로 외부 시스템과의 통신 경로를 제한하고 싶은 경우에도 유용하다.

한편 이용할 때는 Kafka REST Proxy가 데이터 파이프라인의 병목이 되지 않도록 주의해야 한다. 카프카 클러스터는 브로커 대수를 늘려 처리 성능을 향상하는 스케일아웃 방식을 채용하고 있다. 그러나 카프카 클러스터에 비해 Kafka REST Proxy의 처리 성능이 낮으면 Kafka REST Proxy 송수신 처리가 따라가지 못해 카프카 클러스터의 능력을 충분히 살릴 수 없는 경우가 있다. 따라서 Kafka REST Proxy 사이징도 카프카 클러스터와 함께 고려하여 필요에 따라 로드 밸런서와 조합해서 여러 대의 서버를 마련하는 등의 노력이 필요하다.

---

### 6.2.3 데이터 파이프라인의 컨수머 구성 요소

카프카를 이용한 데이터 파이프라인의 컨수머 쪽 구성요소를 살펴본다. 프로듀서 쪽과 마찬가지로 두 가지 패턴을 분류할 수 있다.

1. 미들웨어가 직접 카프카에서 메시지를 취득해 처리하는 패턴
2. 미들웨어가 다른 도구를 통해 카프카에서 메시지를 취득하고 처리/보관하는 패턴

컨수머 쪽에 대해서도 각각의 패턴을 살펴보자.

#### 1. 미들웨어가 직접 카프카에서 메시지를 취득해 처리하는 패턴

데이터를 처리하거나 기록하는 미들웨어가 카프카에서 메시지를 수신하는 패턴이다. 이 패턴은 배치 처리와 스트림 처리를 모두 대응할 수 있지만 카프카가 스트림 데이터를 취급하는 기반이기 때문에 특히 스트림 처리에서 많이 볼 수 있다.

카프카에서 직접 메시지를 취득해 처리하는 미들웨어에는 스트림 처리에 대응하고 있는것이 많다. 프로듀서 쪽에서 소개한 스파크나 병렬 분산 스트림 처리가 가능한 Apache Flink가 대표적이다. 또한 스파크 같은 일부 미들웨어는 카프카에서 직접 데이터를 얻을 수 있으며 스트림 처리와 배치 처리를 모두 지원하고 있다. 스파크의 스트림 처리 매커니즘인 Structured Streaming을 이용한 스틀미 처리 예는 9장에서 소개한다.

이 방식에서는 대부분의 경우 연계하는 외부 시스템이나 파일시스템 등에 처리 결과가 출력되지만 처리한 결과를 다시 카프카에 출력하는 경우도 있다. 예를 들면 전처리를 실시한 스트림데이터를 다른 스트림 처리 애플리케이션에서 사용하는 경우다. 이 경우 해당 애플리케이션은 카프카에서 메시지를 취득해 처리하는 컨수머인 동시에, 한편으로는 처리한 결과를 카프카에 송신하는 프로듀서라고도 할 수 있다. Kafka Streams나 아파치 스파크는 이러한 카프카에서의 읽기와 쓰기를 모두 지원하고 있다.

#### 2. 미들웨어가 다른 도구를 통해 카프카에서 메시지를 취득하고 처리 및 보관하는 패턴

이 패턴은 데이터를 처리하고 기록하는 시스템 또는 미들웨어가 카프카에서 메시지 수신을 지원하지 않아 다른 도구로 카프카에서 메시지를 수신한 후 원하는 시스템에 데이터를 전달하는 방식이다. 프로듀서 쪽과 마찬가지로 데이터를 처리하거나 기록하는 시스템이 카프카를 지원하는 경우에도 시스템 요구 사항에 따라 이 방식을 채택하는 경우도 있다.

특정 용도에 특화한 것을 포함, 이 역할을 해내는 도구는 여럿 있지만 그중에서도 특히 많이 사용하는 것이 Kafka Connect와 Fluentd다. 이들은 프로듀서 쪽에서 사용되는 도구로 소개했으나 커넥터나 플러그인을 변경하여 컨수머 쪽 도구로도 사용할 수 있다. 따라서 사용하는 미들웨어에 따라 프로듀서와 컨수머 양쪽 모두에서 사용할 수도 있다.

---

### Kafka Connect와 Kafka Streams에 의한 데이터 파이프라인

카프카를 폭넓게 적용하는 사례가 많아 카프카와 연계하여 사용할 수 있는 도구와 미들웨어도 늘어나고 있다. 카프카를 적용하는 사례가 늘면서 다양한 형태의 데이터 파이프라인 디자인 패턴이 제안되고 있다. 그리고 그러한 디자인 패턴의 하나로 컨플루언트는 Kafka Connect와 Kafka Streams를 이용한 데이터 파이프라인을 제시하고 있다.

이 패턴에서는 다음과 같은 흐름으로 데이터를 수집하고 처리한다.

1. Kafka Connect를 이용하여 외부에서 카프카로 데이터를 송신한다.
2. Kafka Streams를 이용하여 필요한 데이터를 처리하고 처리 결과를 카프카에 송신한다.
3. Kafka Connect를 이용하여 연계 시스템에 데이터를 출력한다.

이 디자인 패턴은 Kafka Connect와 Kafka Streams를 조합해서 간단하게 구현할 수 있다고 말한다. Kafka Connect의 처리 정보가 모두 카프카 클러스터에 기록되므로 데이터베이스 같은 다른 데이터 저장소가 필요 없는 것도 장점이다. 최근에는 Kafka Streams를 래핑하여 스트림 처리를 SQL처럼 작성할 수 있는 KSQL이 등장해 더 쉽게 데이터 파이프라인을 구축할 수 있게 되었다.

물론 실제 사용에 있어서 적합한 제품은 처리 내용이나 연계하는 다른 시스템에 따라 다르겠지만, 이러한 디자인 패턴을 참고로 각 상황에 맞는 제품을 선택하고 아키텍처를 설계하면 좋을 것이다.

---

## 6.3 데이터 파이프라인에서 취급하는 데이터

### 6.3.1 데이터 파이프라인에서 처리 특성

카프카를 사용한 데이터 파이프라인에서는 취급하는 데이터 자체도 중요한 요소다. 카프카를 사용한 데이터 파이프라인의 애플리케이션이나 스트림 처리에는 다음과 같은 특성이 있다.

#### 1. 여러 미들웨어나 애플리케이션에서 데이터를 읽고 쓴다.

여러 미들웨어나 애플리케이션에서 데이터를 읽고 쓴다는 것은 데이터 파이프라인의 특성이다. 카프카를 중심으로 하는 데이터 파이프라인에는 프로듀서와 컨수머가 있고 프로듀서가 송신한 데이터를 컨수머가 수신해서 이용한다. 대부분의 경우에서 프로듀서와 컨수머는 서로 다른 애플리케이션이며 거기서 다루는 데이터는 당연히 프로듀서, 컨수머 양쪽 모두 취급해야 한다. 5장에서 대표적 기능 중 하나로 소개한 데이터 허브는 여러 애플리케이션에서 데이터를 이용할 것을 염두에 둔 구조다. 이러한 이용 패턴에 따라 더 많은 애플리케이션이 동일한 데이터를 취급하고 처리할 수 있도록 해야 한다.

예를 들어 이 장 앞에서 소개한 웹 서비스의 사용자 액세스 로그 분석에서 프로듀서 쪽 웹 서버가 기록하는 데이터 형식으로 컨수머 쪽에서 분석한다. 이때 웹 서버의 액세스 로그 기록 방법이 예상과 다른 형식으로 변경되면 컨수머 쪽 분석을 올바르게 할 수 없다. 따라서 프로듀서 쪽이 출력하는 데이터와 컨수머 쪽이 전제로 하는 데이터는 일관성이 있어야 한다.

#### 2. 애플리케이션은 항상 실행 상태로 데이터를 처리한다.

이것은 스트림 데이터나 스트림 처리의 특성이다. 스트림 데이터는 계속 생성되기 때문에 데이터를 수신하는 애플리케이션도 계속 처리해야 한다. 특히 다루는 데이터 양이 많으면 항상 파이프라인에 데이터가 흘러가므로 스트림 처리가 이루어지고 있는 상태가 된다. 배치 처리에서는 1회 처리가 모두 완료한 시점(정지점)에서 유지보수를 실시하는 설계를 자주 볼 수 있지만 스트림 처리에서는 그런 설계가 어렵다.

이 장의 첫머리에서 소개한 웹 서비스 사용자 분석에서는 데이터 파이프라인에서 웹 서비스 액세스 로그나 애플리케이션 로그를 수집해 분석에 이용하기로 했다. 웹 서비스는 액세스 수의 증감은 있지만 항상 서비스를 제공하는 경우가 많다. 그렇기에 웹 서비스는 액세스 로그나 애플리케이션 로그도 항상 생성한다. 따라서 그런 데이터를 수집하고 처리하는 데이터 파이프라인은 항상 동작한다. 이러한 데이터 파이프라인에서의 처리 방법은 파이프라인을 구성하는 기반이나 애플리케이션, 취급하는 데이터를 설계할 때 고려해야한다. 여기에서는 그중에서도 많은 구성 요소에 영향을 미치는 3가지 요소를 소개한다.

1. 메시지 데이터 형태
2. 스키마 구조를 갖는 데이터 형태 및 스키마 에볼루션
3. 데이터 표현 방법

이 절에서 소개한 여러 미들웨어나 애플리케이션에 의해 데이터가 읽고 쓰인다는 특성은 이 절에서 소개한 1번 특징은 이 3가지 요소에 영향을 준다. 더불어 2번 특징은 스키마 에볼루션을 더욱 어렵게 한다. 이 부분은 6.3.4절에서 설명한다.

### 6.3.2 메시지 데이터 형태

카프카를 이용한 데이터 파이프라인에서는 카프카를 경유하여 메시지를 송수신하는데, 이 메시지의 데이터 형태는 프로듀서와 컨수머에서 불일치하지 않도록 해야 한다.

메시지는 프로듀서에서 처리되고 데이터 파이프라인 안의 카프카 클러스터로 송신된다. 이때 프로듀서에서 송신되는 메시지의 Key, Value 데이터 형태가 각각 프로듀서 애플리케이션에서 지정되고 데이터를 직렬화해서 송신한다. 그리고 컨수머는 미리 프로듀서에서 보낸 메시지의 Key, Value 데이터 형태와 포함된 데이터를 감안하여 설계하고 구현해야 한다.

이처럼 데이터를 송신하는 쪽과 데이터를 수신하는 쪽에서 데이터 형태가 일치해야 하는 것은 스트림 데이터를 다루는 데이터 파이프라인에만 국한된 이야기가 아니다. 예를 들어 배치처리에서 데이터베이스에 기록되는 데이터도 각 칼럼의 데이터 형태와 데이터를 이해한 후 처리해야 한다. 그러나 카프카에서는 데이터 형태를 관리하고 있지 않기 때문에 카프카 클러스터에서 데이터 형태가 다른 것을 확인하지 못하고 컨수머가 메시지를 수신하여 역직렬화나 데이터 처리하고 난 뒤에 발견되는 경우가 있다. 따라서 데이터 형태를 인식해 데이터를 관리하고 처리할 수 있는 RDBMS와 같은 기반에 비해 주의가 필요하다.

컨수머뿐만 아니라 송신하는 프로듀서에서도 메시지 데이터 형태에 주의가 필요하다. 컨수머가 사용하는 시리얼라이저는 Key, Value마다 1개씩이며 데이터에 따라 구분해서 사용하기 어렵다. 따라서 프로듀서에서 보낸 메시지의 데이터 형태를 변경하려면 그에 해당하는 컨수머도 변경해야 한다. 그러나 애플리케이션은 항상 데이터를 처리하고 있어 쉽게 중단시킬 수 없는 경우가 있다. 또한 데이터 허브같은 사례는 여러 프로듀서, 컨수머가 메시지를 수신하고 있기 때문에 유지보수가 필요한 범위가 더욱 넓어져 대응하는 데 더욱 어렵게 만든다.

이런한 데이터의 불일치를 방지하기 위해 데이터 형태 관리나 향후 확장을 위한 변경 방법에 대해서는 미리 방안을 마련할 필요가 있다. 다음 절에서 소개하는 스키마 구조를 갖는 데이터 형태를 이용하는 것도 대책 중 하나다.

### 6.3.3 스키마 구조를 갖는 데이터 형태

다루는 데이터나 요구 사항에 따라 하나의 메시지에 려러 값을 포함시키고 싶은 경우가 있다. 이러한 경우 데이터 스트림과 스트림 처리에서는 JSON이나 Apache Avro와 같은 구조화된 데이터가 자주 사용된다. 여러 칼럼을 가진 스키마를 정의하여 하나의 메시지 안에 여러 값을 포함할 수 있게 된다.

디바이스의 위치 정보를 생각해보자. 이때 다뤄야 할 정보는 단일값이 아닌 디바이스 ID, 시간, 위도, 경도 같은 값을 하나의 모음 구조로 한 사례가 많다. 이러한 데이터를 사용하여 여러값을 한꺼번에 처리할 수 있다. 스키마 정의는 메시지를 송신하는 프로듀서 애플리케이션 설계에서 사용되지만 컨수머 애플리케이션에 미치는 영향이 크기 때문에 확장성을 고려하여 신중하게 결정해야 한다.

### 6.3.4 스키마 에볼루션

이렇듯 스키마 정의는 신중히 고려해야 하지만 애플리케이션 수정이나 기능 추가에 따라 정의를 변경해야 하는 경우가 발생할 수 있다. 스키마 정의를 운용 중 변경하는 것을 **스키마 에볼루션** 또는 **스키마 진화**라고 한다.

데이터 파이프라인의 스트림 처리에서는 계속적으로 발생하는 데이터를 처리하기 때문에 애플리케이션을 마음대로 중지시킬 수 없는 경우가 많다. 그러므로 스키마 에볼루션에 동반하여 정지할 애플리케이션의 수나 정지 시간을 최소화해야 하는 경우가 많다. 이러한 문제에 대한 대응으로 스키마 에볼루션을 진행할 때 스키마 변경 전후의 호환성을 고려하게 된다.

앞서 소개한 Apache Avro는 호환성을 고려할 수 있는 데이터 형태로, 전방 호환성, 후방 호환성 등 일부 호환성의 종류도 선택할 수 있다. 확장성을 고려해야 하는 경우는 이러한 데이터 형태도 선택할 수 있는 대안 중 하나다. Apache Avro를 데이터 형태로 사용하는 예와 스키마 에볼루션 예는 7장에서 소개한다.

### 6.3.5 데이터 표현 방법

지금까지 데이터 형태의 중요성과 스키마 구조를 지닌 데이터 형태에 대해 소개했다. 마찬가지로 데이터 파이프라인에서는 데이터의 표현 방법도 중요하다.

여기서 말하는 데이터 표현 방법이란 각 정보를 표현하는 방법을 의미한다. 예를 들어 날짜를 표현하는 경우에도 UnixTime이나 문자열 표현 등 여러 방식이 있을 수 있다. 문자열로 표현하는 경우에도 '2018/10/12 01:42:32'와 같은 반각 문자를 사용하거나 '2018년 10월 12일 오전 1시 42분 32초'와 같이 한글 문자를 사용하는 등 시스템에 따라 다양하게 표현할 수 있다.

이러한 정보를 데이터 파이프라인 안의 카프카에서 다룰 때는 올바른 데이터 형태로 직렬화하면 송신은 가능하지만 각각의 표현 방법에 맞는 처리가 필요해 데이터 활용에 방해될 수 있다. 앞 절에서 소개한 스키마 구조를 갖는 데이터 형태를 채용함으로써 관리할 수 있는 것도 있지만, 본질적인 대책은 데이터 파이프라인 쪽의 시스템만으로는 어렵고 데이터의 표현 방법에 규칙을 정해 각 시스템이 그에 따르도록 하는 노력이 필요하다.

---

### Schema Registry

Schema Registry는 컨플루언트가 오픈소스로 개발하고 있는 스키마 정보 관리 도구다.

Apache Avro 이용을 전제로 한 스키마 관리 기능을 제공하고 있으며, 함께 제공된느 전용 시리얼라이저/디시리얼라이저와 Kafka REST Proxy와 함께 사용한다. 프로듀서 쪽에서 메시지가 직렬화될 때 스키마 정보가 Schema Registry에 등록되며 컨수머 쪽 직렬화할 때 참조된다. 또한 스키마 에볼루션을 의식해서 Apache Avro를 이용한 전방/후방/완전 호환성을 유지하는 기능도 제공된다.

Schema Registry는 데이터 허브처럼 여러 스키마 정의를 관리해야 하는 환경에 좋다. 스키마 정의를 일괄적으로 관리하고 호환성 없는 메시지의 송수신을 방지함으로써 예상치 못한 오류를 방치할 수 있다.

또한 스키마 정의 정보는 Schema Registry가 카프카 전용 토픽에 메시지를 송신함으로써 기록하는 구성으로 되어 있어 다른 데이터 저장소를 준비할 필요가 없다.

Schema Registry는 Kafka REST Proxy와 마찬가지로 공개된 소스를 빌드하거나 컨플루언트 플랫폼에 포함된 패키지를 설치하여 사용할 수 있다. Schema Registry는 7장에서 소개한다.

---

## 6.4 정리

이 장에서는 카프카를 이용한 데이터 파이프 라인을 검토할 때 고려해야 할 대표적인 사항을 살펴봤다. 다음 장부터는 카프카를 이용한 데이터 파이프라인의 전형적인 사용 사례를 소개한다. 이 장은 그 기초에 해당하므로 내용을 잘 기억하고 읽는다면 이해하는데 도움될 것이다.
