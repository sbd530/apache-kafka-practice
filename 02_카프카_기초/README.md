# 2장 카프카 기초

## 2.1 이 장의 내용

이 장에서는 카프카의 메시지 송수신 구조와 카프카를 이용하는 데 알아야 할 기본 용어를 설명한다. <br>카프카는 여러 구성 요소로 이루어져 있어 개별 구성 요소를 파악하는 것만으로는 전체적인 그림을 이해하는 것을 어렵다. 개요부터 시작하여 내부 동작까지 단계적으로 설명한다. 주요내용은 다음과 같다.

    1. 메시지 송수신 기본
    2. 시스템 구성
    3. 분산 메시징을 위한 구조
    4. 데이터 견고함을 담보하는 복제의 구조

## 2.2 메시지 송수신 기본

우선 논리적 구성과 기본 용어를 파악해보자. 카프카의 주요 구성요소는 다음 5가지다.

- 브로커

  - 데이터를 수신, 전달하는 서비스

- 메시지

  - 카프카에서 다루는 데이터의 최소 단위. 카프카가 중계하는 로그의 한 줄 한줄과 센서 데이터 등이 이에 해당. 메시지는 Key와 Value를 갖게 되며 나중에 언급할 메시지 전송할 때 파티셔닝에 이용

- 프로듀서
  - 데이터의 생산자이며 브로커에 메시지를 보내는 애플리케이션
- 컨슈머

  - 브로커에서 메시지를 취득하는 애플리케이션

- 토픽
  - 메시지를 종류(토픽)별로 관리하는 스토리지. 브로커에 배치되어 관리된다. 프로듀서와 컨수머는 특정 토픽을 지정하여 메시지를 송수신함으로써 단일 카프카 클러스터에서 여러 종류의 메시지를 중계한다.<br><br>

## 2.3 시스템 구성

### 브로커

브로커는 하나의 서버(또는 인스턴스) 당 하나의 데몬 프로세스로 동작하여 메시지 수신/전달 요청을 받아들인다. 이것을 여러 대의 클러스터로 구성할 수 있으며 브로커(리소스)를 추가함으로써 수신/전달의 처리량 향상(스케일 아웃)이 가능하다.<br>
브로커에서 받은 데이터는 모두 디스크로 내보내기(영속화)가 이루어져 디스크의 총 용량에 따라 장기간 데이터를 보존할 수 있다.<br><br>

### 프로듀서 API/컨수머 API

프로듀서/컨수머를 구현하는 기능은 브로커로 데이터를 보내고 브로커에서 데이터를 받기 위한 '라이브러리'로 제공된다. 프로듀서를 구현하기 위한 API를 프로듀서 API, 컨수머를 구현하기 위한 API를 컨수머 API라고 한다. 프로듀서, 컨수머는 브로커처럼 서비스(데몬 프로세스)로 작동하는 프로그램이 아니다. 각각의 API는 자바로 제공된다.<br><br>

### 프로듀서

프로듀서는 프로듀서 API를 이용하여 브로커에 데이터를 송신하기 위해 구현된 애플리케이션이다. 실제 사례로는 각종 로그 전송 및 미들웨어와 연동하여 동작하기 때문에 프로듀서 API를 내포한 도구, 미들웨어를 통해 이용하는 형태 등 다양하다.<br>
실제로 프로듀서 기능을 내장하거나 서드 파티의 플러그인 제휴를 통해 제공하는 OSS(Open Source Software), 도구의 종류는 다음과 같다.<br>

- Apache Log4j(Kafka Appender)

  - 로그 출력시 사용하는 자바 기반 로깅 유틸리티 소프트웨어
  - Kafka Appender

- Apache Flume

  - 다량의 로그 데이터를 효율적으로 수집, 취합, 이동하기 위한 분산형 소프트웨어
  - Kafka Sink

- Fluentd

  - 크로스 플랫폼 오픈소스 데이터 수집 소프트웨어
  - fluent-plugin-kafka

- Logstash
  - 일래스틱에서 제공하는 OSS 데이터 수집 엔진
  - logstash-output-kafka

### 컨수머

컨수머 API를 이용해 브로커에서 메시지를 취득하도록 구현된 애플리케이션이다. 브로커는 앞서 말한 대로 메시지를 디스크에 영속화하기 위해 브로커에 도달하는 즉시 컨수머에서 취득해야 하는 제약이 없어 디스크에 보관되어 있는 동안은 메시지 취득이 가능하다. 일정 기간 데이터를 축적한 스토리지에서의 데이터 추출 및 실시간 처리를 위한 애플리케이션의 데이터 입력 등으로 이용된다.<br><br>
프로듀서와 마찬가지로 카프카 연계를 위한 컨수머 기능을 갖춘 기존 제품도 많이 존재한다. 특히 Apache Spark(Streaming), Apache Storm, Apache Flink 등의 분산 스트림 처리 OSS에서는 카프카가 갖춘 확장성을 유용하게 사용할 경우가 많기 때문에 표준 라이브러리로 제공되고 있다.

### 주키퍼

카프카의 브로커에 있어 분산 처리를 위한 관리 도구로 아파치 주키퍼가 필요하다. 주키퍼는 하둡 등 병렬 분산 처리용 OSS에 있어서 설정 관리, 이름 관리, 동기화를 위한 잠금 관리를 하는 구조로 자주 사용된다. 카프카에 있어서는 분산 메시징의 메타데이터(토픽과 파티션 등)를 관리하기 위한 구성 요소로 기능한다. 주키퍼 클러스터(주키퍼 앙상블)의 구조상 3, 5처럼 홀수로 구성하는 것이 일반적이다.

### 카프카 클라이언트

토픽 작성 등 카프카의 동작 및 운영 상에 필요한 조작을 실행하는 서버다. 메시지의 송수신을 처리하는 서버가 아니다.

### 카프카 클러스터

위에서 언급한 바와 같이 카프카는 여러 대의 브로커 서버, 주키퍼 서버로 이루어진 클러스터링의 메시지 중계 기능과 메시지 송수신을 위한 라이브러리 그룹(프로듀서API/컨수머API)으로 구성된다. 이 책에서는 설명을 위해 전자의 브로커, 주키퍼에 의해 구성된 클러스터 시스템을 **카프카 클러스터**라고 정의한다.

## 2.4 분산 메시징을 위한 구조

### 파티션

토픽에 대한 대량의 메시지 입출력을 지원하기 위해, 브러커상의 데이터를 읽고 쓰는 것은 파티션이라는 단위로 분할되어 있다. 토픽을 구성하는 파티션은 브로커 클러스트 안에 분산 배치되어 프로듀서에서의 메시지 수신, 컨수머로의 배달을 분산해서 실시함으로써 하나의 토픽에 대한 대규모 데이터 수신과 전달을 지원한다.

각 파티션을 브로커에 어떻게 배치하는가에 대한 정보는 브로커 측에 유지된다. 또한 프로듀서API/컨수머API가 파티션들을 은폐해서 통신하기 때문에 프로듀서/컨수머에서는 토픽만을 지정하고,구현 시에 송신처 파티션을 의식할 필요가 없다.

### 컨수머 그룹

카프카는 하류 시스템(컨수머)에서 분산 스트림 처리도 고려해 설계되어 있다. 단일 애플리케이션 안에서 여러 컨수머가 단일 토픽이나 여러 파티션에서 메시지를 취득하는 방법으로 컨수머 그룹이라는 개념이 존재한다.

카프카 클러스터 전체에서 글로벌 ID를 컨수머 그룹 전체에서 공유하고 여러 컨수머는 자신이 소속한 컨수머 그룹을 식별해, 읽어들일 파티션을 분류하고 재시도를 제어한다.

### 오프셋

각 파티션에서 수신한 메시지에는 각각 일련번호가 부여되어 있어 파티션 단위로 메시지 위치를 나타내는 오프셋이라는 관리정보를 이용해 컨수머가 취득하는 메시지의 범위 및 재시도를 한다. 제어에 사용되는 오프셋에는 다음과 같은 것이 있다.

- Log-End-Offset(LEO) : 파티션 데이터의 끝을 나타낸다.
- Current Offset : 컨수머가 어디까지 메시지를 읽었는가를 나타낸다.
- Commit Offset : 컨수머가 어디까지 커밋했는지를 나타낸다.

LEO는 브로커에 의해 파티션에 관한 정보로 관리 및 업데이트된다. Commit Offset은 컨수머 그룹마다 보관되어 관리, 업데이트된다. Current Offset은 컨수머에서의 데이터 취득을 계기로 업데이트된다.

Commit Offset은 컨수머로부터 '여기까지의 오프셋은 처리했다'는 것을 확인하는 오프셋 커밋 요청을 계기로 업데이트된다. 특정 토픽에 대해 여러 컨수머 그룹이 메시지를 취득하는 경우 파티션에 대한 Commit Offset도 컨수머 그룹 숫자만큼만 존재한다.

## 2.4.1 메시지 송수신

카프카에 있어서 메시지 송신은 반드시 하나하나의 메시지 단위로 송수신하는 것은 아니다. 송수신 처리량을 높이기 위해 어느 정도 메시지를 축적하여 배치 처리로 송수신하는 기능 또한 제공한다.

### 프로듀서의 메시지 송신

프로듀서가 토픽의 파티션에 메시지를 송신할 때 버퍼 기능처럼 프로듀서의 메모리를 이용하여 일정량을 축적 후 송신할 수 있다. 데이터의 송신에 대해서는 지정한 크기까지 메시지가 축적되거나, 지정한 대기 시간에 도달하는 것 중 하나를 트리거로 전송한다.

기본 설정으로 하나의 메시지는 1회 송신되지만, 수 바이트에서 수십 바이트의 작은 메시지를 대량으로 브로커에 송신하는 상황에서는 네트워크의 지연이 처리량에 영향을 주는 경우도 있어 메시지를 배치로 송신함으로써 처리량을 향상시킨다. 크기가 큰 텍스트 파일과 로그 파일에 포함된 각 레코드를 한 행 한행 브로커에 송신하는 겨우에도 여러 행을 모아서 배치 송신함으로써 처리량을 향상시키는 효과를 기대할 수 있다.

### 컨수머의 메시지 취득

컨수머의 취득 대상의 토픽과 파티션에 대해 Current Offset으로 나타나는 위치에서 마지막으로 취득한 메시지부터 브로커에서 보관하는 최신 메시지까지 모아서 요청 및 뒤득을 실시하고, 그것을 반복함으로써 계속적인 메시지 취득을 반복한다. 즉, 메시지의 유입 빈도가 동일한 경우 컨수머의 브로커 요청 간격이 길수록 모인 메시지가 많아진다.
<br><br>

_작은 범위로 요청을 하는 경우_

요청으로 하나의 메시지를 취득하는 경우, 하나의 메시지마다 Current Offset을 업데이트한다.<br><br>

_일정 간격을 두고 요청하는 경우_

하나의 요청으로 5개의 메시지를 취득할 경우, 5개의 메시지만큼 Current Offset을 업데이트한다.
<br><br>
프로듀서, 컨수머에서도 어느 정도 메시지를 모아 배치 처리함으로써 처리량을 향상시키는 효과는 기대할 수 있지만 프로듀서 송신과 컨수머 수신 처리의 지연 시간은 증가한다. 취급하는 데이터와 시스템에 따라 밀리초에서 초 단위의 지연 시간도 바람직하지 않은 경우도 있따. 그러므로 배치 처리의 간격에 대해서는 처리량과 대기 시간의 트레이드오프를 고렿나 설계가 필요하다.

## 2.4.2 컨수머의 롤백

컨수머는 위에서 언급한 바와 같이 오프셋을 진행하면서 지속적으로 메시지를 취득하지만, Offset Commit의 구조를 이용해 컨수머 처리 실패, 고장 시 롤백 메시지 재취득을 실현한다.

주의해야할 점은 Commit Offset까지 되돌아온 오프셋 간 메시지에 대한 대처는 후속 애플리케이션에 맡긴다는 점이다.

메시지를 처리 완료 상태에서 Commit Offset 업데이트 직전의 고장의 경우는 동일한 메시지가 재전송되고, 메시지 중복 처리(또는 중복 허용)가 필요하다.

이 재시도는 Exactly Once가 아니라 At Least Once로 송신하는 구조다. 또한 고장의 감지, 복구에 대해서도 카프카에서 제공되는 것은 아니기 때문에 Comsumer API를 이용한 애플리케이션 쪽에서의 대처가 필요하다. 다행히도 Spark Streaming 등 카프카 연계 기능을 제공하는 대부분의 분산 처리 프레임워크는 컨수머의 고장이나 장애를 감지하여 재실행하는 메커니즘이 있으므로 일반 사용자가 감지하여 재실행하는 경우는 드물다.<br><br>

> ## 브로커의 데이터 보관 기간
>
> ### 오래된 메시지 삭제
>
> 축적된 메시지 중 오래된 것부터 삭제한다. 삭제의 동기(삭제 트리거)에 대해서는 메시지 취득 후 경과 시간, 데이터 크기 두 가지로 설정 가능하다.
>
> - 데이터 취득 후 경과 시간을 트리거로 할 경우 : 시간, 분, 밀리초 등으로 지정할 수 있다. 지저한 시간보다 오래된 데이터가 삭제된다(기본:168시간(1주일))
> - 데이터 크기를 트리거로 한 경우 : 축적 데이터가 지정한 데이터 크기보다 커진 경우 데이터가 삭제된다(기본:-1(크기 제한 없음))
>   <br>
>
> ### 압축
>
> 최신 Key의 데이터를 남겨두고 중복하는 Key의 오래된 메시지가 삭제된다. 동일한 Key에 대해서는 항상 최신의 Value만 얻을 수 있으면 되는 상황에서 사용할 수 있다.<br>
> 이용 상황의 예로는 RDBMS의 INSERT 또는 UPDATE된 레코드를 카프카에서도 수신한다는 경우를 들 수 있다. UPDATE에 의해 행 갱신된 경우 UPDATE 후의 최신 값만 취득할 수 있으면 된다면 '오래된 데이터 삭제' 설정이 아닌 '압축' 설정을 함으로써 디스크 용량과 I/O를 효율적으로 이용하면서 각 Key의 최신(또는 최신을 포함하는) 레코드를 계속 유지할 수 있다.
> <br><br>
> 오래된 메시지를 삭제하거나 압축하는 것은 브로커의 파라미터인 cleanup.policy로 delete 또는 compact 값을 설정하는 것이 가능하다.

<br><br>

## 2.5 데이터의 견고성을 높이는 복제 구조

카프카는 메시지를 중계함과 동시에 서버가 고장 났을 때에 수신한 메시지를 읽지 않기 위해 복제(Replication) 구조를 갖추고 있다. 토픽과 파티션은 여러 개 있는 것이 일반적이며, 여러 대의 브로커에 토픽 구성 파티션과 레플리카가 배치된다.<br>
파티션은 단일 또는 여러 개의 레플리카로 구성되어 토픽 단위로 레플리카 수를 지정할 수 있다. 또한 레플리카 중 하나는 Leader이며, 나머지는 Follower라고 불린다. Follower는 그 이름대로 Leader로부터 메시지를 계속적으로 취득하여 복제를 유지하도록 동작한다. 다만 프로듀서/컨수머와의 데이터 교환은 Leader가 맡고 있다.

### 2.5.1 레플리카의 동기 상태

Leader Replica의 복제 상태를 유지하고 있는 레플리카는 In-Sync Replica로 분류된다. In-Sync Replica는 카프카의 문서나 콘솔 출력에서는 ISR로 표기되는 경우도 있다. 모든 레플리카가 In-Sync Replica로 되어 있지 않은 파티션을 Under Replicated Partitions라고 부른다. 또한 복제 수와는 독립적으로 최소 ISR 수 (min.insync.replica) 설정이 가능하며, 고장 등으로 인한 일시적인 동기 지연을 허용하여 전체 읽고 쓰기를 계속하는 것이 가능하다.

### 2.5.2 복제 완료 최신 오프셋(High Wartermark)

복제 사용시 오프셋 관리에는 LEO(Log End Offset) 이외에 High Watermark라는 개념이 있다. High Watermark는 복제가 완료된 오프셋이며, 그 성질에서 반드시 LEO와 동일하거나 오래된 오프셋을 나타낸다. 컨수머는 Hign Watermark까지 기록된 메시지를 취득할 수 있다.

### 2.5.3 프로듀서의 메시지 도달 보증 수준

복제에 대한 중요한 구성 요소로 프로듀서의 메시지 송신 시 Ack 설정에 대해 설명한다. 브로커에서 프로듀서로 메시지가 송신된 것을 나타내는 Ack를 어느 타이밍에 송신할 것인지를 제어하는 것은 성능과 내장애성(브로커 서버 고장 시 데이터 분실 방지)에 큰 영향을 준다. Ack는 아래와 같이 3종류로 설정이 가능하다.<br><br>

| Ack 설정 | 설명                                                                  |
| -------- | --------------------------------------------------------------------- |
| 0        | 프로듀서는 메시지 송신 시 Ack를 기다리지 않고 다음 메시지를 송신한다. |
| 1        | Leader Replica에 메시지가 전달되면 Ack를 반환한다.                    |
| all      | 모든 ISR의 수만큼 복제되면 Ack를 반환한다.                            |

<br>

프로듀서는 타임 아웃 설정으로 Ack가 돌아오지 않고 타임아웃된 Send 처리를 '송신 실패'로 감지한다.<br>
참고로 Ack를 1 또는 all로 설정했을 경우 Ack 반환 타이밍이 의미하는 것은 각 복제에 '메시지가 전달'된 것으로 판단해 Ack를 반환하는 타이밍이다. 그리고 이 타이밍에는 메시지가 디스크에 flush되는 것이 아니라 메모리(OS 버퍼)에 기록된다. 디스크에 flush하는(영속화하는) 타이밍은 다른 속성에서 제어한다.

### 2.5.4 In-Sync Replica와 Ack = all, 쓰기 계속성의 관계

복제 수와 별도로 최소 ISR 수를 제어함으로써 쓰기에 어떤 제어를 할 수 있을까? ISR과 Ack의 설정에 따라 프로듀서의 쓰기 동작의 예를 다음의 두가지 패턴으로 설명한다. 두 패턴 모두 브로커는 4대, 레플리카 수는 3으로, 브로커 1대가 고장나 레플리카를 하나 잃어버린 경우를 예로 비교한다.

1. min.insync.replicas=3 (레플리카 수와 동일), Ack=all 인 경우<br>
   브로커 서버가 1대 고장난 경우 프로듀서는 비정상 상태로 간주하여 잃어버린 레플리카가 ISR로 복귀할 때까지 데이터를 쓸 수 없다.
2. min.insyc.replicas=2, Ack=all 인 경우<br>
   브로커 서버가 1대 고장난 경우에도 Ack를 반환하고 처리를 계속한다. 처리를 계속하는 점에 있어서는 1.의 경우보다 나은 반면, 나중에 추가된 파티션이 복제를 완료해 ISR로 승격될 때까지 복제 수가 2가 된다. 복구 전에 2대가 고장난 경우는 처리 중인 메시지를 손실할 위험이 높아진다.

위에서 언급한 바와 같이 min.insync.replicas 설정은 서버 고장시 '데이터(메시지)를 잃지 않는 것'과 '메시징 시스템을 포함한 전체 시스템의 처리를 계속하는 것' 사이의 균형을 조정하는 설정 항목이라고 할 수 있다. 예로 들어 두 가지 경우는 어느 쪽이 뛰어나다는 것이 아니라 시스템 요구 사항과 제약 조건에 의해 결정돼야 한다는 점에 주의해야 한다.

## 2.6 정리

카프카의 특징과 장점을 요약하면 다음과 같다.<br><br>

- 스케일 아웃 구성<br>
  \- 메시지를 중계하는 브로커를 여러 대 구성할 수 있으며, 브로커 수를 증가함으로써 클러스터 전체의 처리량을 증가시킬 수 있다.

- 데이터의 디스크 영속화<br>
  \- 브로커에서의 수신한 메시지는 디스크에 기록되어 영속화된다. 디스크 용량에 따라 장기간의 과거 데이터를 저장, 재취득이 가능하다.

- 연계할 수 있는 제품 존재<br>
  \- 프로듀서/컨수머를 구현하기 위한 API가 제공되어 이를 구현한 OSS가 많이 존재한다.

- 메시지의 도달 보증<br>
  \- Ack와 Offset Commit 방식으로 메시지가 제대로 송수신되었음을 확인하고 실패 시 재시도를 허용한다.
